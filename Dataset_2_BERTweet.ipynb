{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7061f08-0c8d-41b1-b86e-46ef1364ff30",
   "metadata": {},
   "source": [
    "### BERTweet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe4a11c-ad7e-42f6-a6e7-a5023a1228e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a13969-8743-49be-985d-965800f39b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is built with MPS\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_built():\n",
    "    print(\"PyTorch is built with MPS\")\n",
    "else:\n",
    "    print(\"MPS not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dffbcb4f-8f60-4237-b875-2b2883de7570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"MPS device not found\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e06e15-9234-4bdf-a10d-f72936bda253",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#torch.set_default_device('mps')\n",
    "\n",
    "mod = torch.nn.Linear(20,30)\n",
    "print(mod.weight.device)\n",
    "print(mod(torch.randn(128, 20)).device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f3a1f-a5ab-432c-82fa-aa4dd753e1da",
   "metadata": {},
   "source": [
    "## PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a64cdee4-6c48-4bf8-b9eb-9c1ab4e34705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic utilities\n",
    "import os\n",
    "import platform\n",
    "\n",
    "# Data handling and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Text preprocessing and sentiment analysis utilities\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "# Visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn utilities for model evaluation, data splitting, and metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, f1_score, recall_score, \n",
    "                             precision_score, confusion_matrix, classification_report, \n",
    "                             precision_recall_fscore_support)\n",
    "\n",
    "# Transformers and HuggingFace utilities\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, \n",
    "                          TrainingArguments, Trainer, AutoConfig)\n",
    "\n",
    "# Optimization tools\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b72368dd-5621-49cf-8d59-736b47939fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine: arm64\n",
      "Platform: macOS-13.5-arm64-i386-64bit\n",
      "Mac Version: ('13.5', ('', '', ''), 'arm64')\n",
      "Processor: i386\n",
      "Python Version: 3.11.4\n"
     ]
    }
   ],
   "source": [
    "def general_info():\n",
    "    print(\"Machine:\", platform.machine())\n",
    "    print(\"Platform:\", platform.platform())\n",
    "    print(\"Mac Version:\", platform.mac_ver())\n",
    "    print(\"Processor:\", platform.processor())\n",
    "    print(\"Python Version:\", platform.python_version())\n",
    "  \n",
    "general_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d025ea65-b5e1-4b54-84d0-0427045c722d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Jupyter core packages...\n",
      "IPython          : 8.12.0\n",
      "ipykernel        : 6.19.2\n",
      "ipywidgets       : 8.0.4\n",
      "jupyter_client   : 7.4.9\n",
      "jupyter_core     : 5.3.0\n",
      "jupyter_server   : 1.23.4\n",
      "jupyterlab       : 3.6.3\n",
      "nbclient         : 0.5.13\n",
      "nbconvert        : 6.5.4\n",
      "nbformat         : 5.7.0\n",
      "notebook         : 6.5.4\n",
      "qtconsole        : 5.4.2\n",
      "traitlets        : 5.7.1\n"
     ]
    }
   ],
   "source": [
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e11c31e-b1c9-4f98-ba71-133e046883bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \n",
       "0                    I`d have responded, if I were going   neutral  \n",
       "1                                               Sooo SAD  negative  \n",
       "2                                            bullying me  negative  \n",
       "3                                         leave me alone  negative  \n",
       "4                                          Sons of ****,  negative  \n",
       "...                                                  ...       ...  \n",
       "27476                                             d lost  negative  \n",
       "27477                                      , don`t force  negative  \n",
       "27478                          Yay good for both of you.  positive  \n",
       "27479                         But it was worth it  ****.  positive  \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral  \n",
       "\n",
       "[27481 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the path to the dataset, load the csv into Pandas DataFrame\n",
    "data_pth = '/users/anshulvij/Desktop/Masters Project Code/Tweets.csv'\n",
    "df = pd.read_csv(data_pth)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feeeecea-875a-41c0-83b7-00255b73b0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of each sentiment:\n",
      "neutral     11118\n",
      "positive     8582\n",
      "negative     7781\n",
      "Name: sentiment, dtype: int64\n",
      "neutral     40.457043\n",
      "positive    31.228849\n",
      "negative    28.314108\n",
      "Name: sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def display_sentiment_counts(dataframe, column_name='sentiment'):\n",
    "    \"\"\"\n",
    "    Display the counts and percentages of unique values in the specified column.\n",
    "    \n",
    "    Args:\n",
    "    - dataframe (pd.DataFrame): The dataframe containing the data.\n",
    "    - column_name (str): The name of the column to compute the statistics for. Default is 'sentiment'.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    sentiment_counts = dataframe[column_name].value_counts()\n",
    "    print(\"\\nCount of each sentiment:\")\n",
    "    print(sentiment_counts)\n",
    "\n",
    "    sentiment_percentages = dataframe[column_name].value_counts(normalize=True)*100\n",
    "    print(sentiment_percentages)\n",
    "\n",
    "display_sentiment_counts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b14ed6c8-0117-4cb3-b33e-4d40467a211e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " textID           0\n",
      "text             1\n",
      "selected_text    1\n",
      "sentiment        0\n",
      "dtype: int64\n",
      "Post Filtering Step-1: Total Rows - 27480\n"
     ]
    }
   ],
   "source": [
    "def check_missing_data(dataframe):\n",
    "    \"\"\"\n",
    "    Check for missing data in the dataframe.\n",
    "    \n",
    "    Args:\n",
    "    - dataframe (pd.DataFrame): The dataframe to inspect.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.Series: A series containing counts of missing data for each column.\n",
    "    \"\"\"\n",
    "    return dataframe.isnull().sum()\n",
    "\n",
    "# Display the number of missing values for each column\n",
    "print(\"Missing Values:\\n\", check_missing_data(df))\n",
    "\n",
    "# Remove rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "print(f\"Post Filtering Step-1: Total Rows - {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d95bed68-41e1-4f93-a2a4-d2d9d52f777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_handle_contractions(text):\n",
    "    \"\"\"\n",
    "    Expand contractions in the provided text using a predefined contractions dictionary.\n",
    "    This function handles contractions formed both with standard apostrophes and backticks.\n",
    "    \n",
    "    Args:\n",
    "    - text (str): The input text containing contractions.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The input text with all recognized contractions expanded.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define a dictionary of contractions and their expanded forms\n",
    "    contractions_dict = contractions.contractions_dict\n",
    "    \n",
    "    # Replace the contractions with their expanded form\n",
    "    for contraction, expansion in contractions_dict.items():\n",
    "        # Handle both apostrophes and backticks\n",
    "        text = text.replace(contraction, expansion)\n",
    "        text = text.replace(contraction.replace(\"'\", \"`\"), expansion)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Applying it to the DataFrame\n",
    "df['text'] = df['text'].apply(custom_handle_contractions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2301ca79-5333-418a-9967-f9782b590b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I would have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why could not they put them on ...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I have wondered about rake to.  The client ha...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1            I would have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why could not they put them on ...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I have wondered about rake to.  The client ha...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \n",
       "0                    I`d have responded, if I were going   neutral  \n",
       "1                                               Sooo SAD  negative  \n",
       "2                                            bullying me  negative  \n",
       "3                                         leave me alone  negative  \n",
       "4                                          Sons of ****,  negative  \n",
       "...                                                  ...       ...  \n",
       "27476                                             d lost  negative  \n",
       "27477                                      , don`t force  negative  \n",
       "27478                          Yay good for both of you.  positive  \n",
       "27479                         But it was worth it  ****.  positive  \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral  \n",
       "\n",
       "[27480 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d68005fd-7192-421d-bab8-907a252db0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean the provided text by removing URLs, mentions, numbers, hashtags, non-ASCII characters, and converting to lowercase.\n",
    "    \n",
    "    Args:\n",
    "    - text (str): The input text.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The cleaned text.\n",
    "    \"\"\"\n",
    "    text = text.lower() \n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'#\\S+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Remove non-ASCII characters\n",
    "    return text\n",
    "\n",
    "df['cleaned_tweets'] = df['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "716c5d28-f40a-407a-96d1-9ad1b8646301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retain_required_columns(df, required_columns):\n",
    "    \"\"\"\n",
    "    Retains only the specified required columns in the DataFrame and drops all others.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "    - required_columns (list): List of column names to retain.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame containing only the required columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if required columns are present in the dataframe\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"The following required columns are not present in the DataFrame: {missing_columns}\")\n",
    "    \n",
    "    return df[required_columns]\n",
    "\n",
    "\n",
    "df = retain_required_columns(df, ['sentiment', 'cleaned_tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "129a4432-899d-4f86-b085-8edd44c2e2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i would have responded if i were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>sons of  why could not they put them on the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>negative</td>\n",
       "      <td>wish we could come see u on denver  husband l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>negative</td>\n",
       "      <td>i have wondered about rake to  the client has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>positive</td>\n",
       "      <td>yay good for both of you enjoy the break  you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>positive</td>\n",
       "      <td>but it was worth it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>neutral</td>\n",
       "      <td>all this flirting going on  the atg smiles ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                     cleaned_tweets\n",
       "0       neutral             i would have responded if i were going\n",
       "1      negative         sooo sad i will miss you here in san diego\n",
       "2      negative                             my boss is bullying me\n",
       "3      negative                      what interview leave me alone\n",
       "4      negative   sons of  why could not they put them on the r...\n",
       "...         ...                                                ...\n",
       "27476  negative   wish we could come see u on denver  husband l...\n",
       "27477  negative   i have wondered about rake to  the client has...\n",
       "27478  positive   yay good for both of you enjoy the break  you...\n",
       "27479  positive                              but it was worth it  \n",
       "27480   neutral     all this flirting going on  the atg smiles ...\n",
       "\n",
       "[27480 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "774aec3f-282f-4e39-832e-37421680c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect all duplicates based on the 'cleaned_text' column\n",
    "duplicates_mask = df.duplicated(subset='cleaned_tweets', keep=False)\n",
    "\n",
    "# Remove all rows with duplicate 'cleaned_text'\n",
    "df = df[~duplicates_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43b57014-9b43-4568-b3f4-2ff06e9dc7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i would have responded if i were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>sons of  why could not they put them on the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>negative</td>\n",
       "      <td>wish we could come see u on denver  husband l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>negative</td>\n",
       "      <td>i have wondered about rake to  the client has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>positive</td>\n",
       "      <td>yay good for both of you enjoy the break  you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>positive</td>\n",
       "      <td>but it was worth it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>neutral</td>\n",
       "      <td>all this flirting going on  the atg smiles ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                     cleaned_tweets\n",
       "0       neutral             i would have responded if i were going\n",
       "1      negative         sooo sad i will miss you here in san diego\n",
       "2      negative                             my boss is bullying me\n",
       "3      negative                      what interview leave me alone\n",
       "4      negative   sons of  why could not they put them on the r...\n",
       "...         ...                                                ...\n",
       "27476  negative   wish we could come see u on denver  husband l...\n",
       "27477  negative   i have wondered about rake to  the client has...\n",
       "27478  positive   yay good for both of you enjoy the break  you...\n",
       "27479  positive                              but it was worth it  \n",
       "27480   neutral     all this flirting going on  the atg smiles ...\n",
       "\n",
       "[27200 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38c599aa-6555-412e-89a2-5018fddfb32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of each sentiment:\n",
      "neutral     11030\n",
      "positive     8435\n",
      "negative     7735\n",
      "Name: sentiment, dtype: int64\n",
      "neutral     40.551471\n",
      "positive    31.011029\n",
      "negative    28.437500\n",
      "Name: sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def display_sentiment_counts(dataframe, column_name='sentiment'):\n",
    "    \"\"\"\n",
    "    Display the counts and percentages of unique values in the specified column.\n",
    "    \n",
    "    Args:\n",
    "    - dataframe (pd.DataFrame): The dataframe containing the data.\n",
    "    - column_name (str): The name of the column to compute the statistics for. Default is 'sentiment'.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    sentiment_counts = dataframe[column_name].value_counts()\n",
    "    print(\"\\nCount of each sentiment:\")\n",
    "    print(sentiment_counts)\n",
    "\n",
    "    sentiment_percentages = dataframe[column_name].value_counts(normalize=True)*100\n",
    "    print(sentiment_percentages)\n",
    "\n",
    "display_sentiment_counts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93e305ce-73dc-4614-a8a1-9bd67336d342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate sentiment frequency and its relative percentage\n",
    "sentiment_frequency = df['sentiment'].value_counts()\n",
    "sentiment_ratio = df['sentiment'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Display sentiment distribution using a bar chart\n",
    "bars = plt.bar(sentiment_frequency.index, sentiment_frequency.values, alpha=0.8)\n",
    "\n",
    "# Adjust the y-axis limit\n",
    "plt.ylim(0, max(sentiment_frequency.values) * 1.15)  # Increase the upper limit by 15% of the highest bar value\n",
    "\n",
    "# Label each bar with the sentiment count and its percentage\n",
    "for idx, bar in enumerate(bars):\n",
    "    yval = bar.get_height()\n",
    "    sentiment_label = sentiment_frequency.index[idx]\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + max(sentiment_frequency.values) * 0.05, \n",
    "             f'{int(yval)} ({sentiment_ratio[sentiment_label]:.2f}%)',\n",
    "             ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Sentiment Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Sentiment Distribution Visualization')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f1c9c83-1c3f-40d4-86d7-8fbb02e0ad44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i would have responded if i were going</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>sons of  why could not they put them on the r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                     cleaned_tweets  target\n",
       "0   neutral             i would have responded if i were going       2\n",
       "1  negative         sooo sad i will miss you here in san diego       1\n",
       "2  negative                             my boss is bullying me       1\n",
       "3  negative                      what interview leave me alone       1\n",
       "4  negative   sons of  why could not they put them on the r...       1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Data Preparation ---\n",
    "\n",
    "# Map the sentiments to numerical values\n",
    "target_map = {'neutral':2,'positive':0,'negative':1}\n",
    "df = df.copy()\n",
    "df.loc[:, 'target'] = df['sentiment'].map(target_map)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65fd9ae5-932b-4910-b081-b4b93b2b1a58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_FPR_spec_metrics(cm, labels=[\"positive\", \"negative\", \"neutral\"]):\n",
    "    \"\"\"\n",
    "    Compute specificity, FPR, precision for each class, and the overall accuracy given a 3x3 confusion matrix.\n",
    "    Also, computes weighted and macro average for FPR and specificity.\n",
    "\n",
    "    Args:\n",
    "    - cm (numpy array): 3x3 confusion matrix\n",
    "    - labels (list): List of class labels in order\n",
    "\n",
    "    Returns:\n",
    "    None. It will print the results directly.\n",
    "    \"\"\"\n",
    "    \n",
    "    specificities = []\n",
    "    fprs = []\n",
    "    precisions = []\n",
    "\n",
    "    for i in range(3):\n",
    "        tp = cm[i, i]\n",
    "        tn = sum(cm[j, j] for j in range(3) if j != i)\n",
    "        fp = sum(cm[j, i] for j in range(3) if j != i)\n",
    "        fn = sum(cm[i, j] for j in range(3) if j != i)\n",
    "        \n",
    "        specificity = tn / (tn + fp) if tn + fp != 0 else 0\n",
    "        fpr = 1 - specificity\n",
    "        precision = tp / (tp + fp) if tp + fp != 0 else 0\n",
    "        \n",
    "        specificities.append(round(specificity, 4))\n",
    "        fprs.append(round(fpr, 4))\n",
    "        precisions.append(round(precision, 4))\n",
    "    \n",
    "    # Print the class values with their corresponding metrics\n",
    "    for i, label in enumerate(labels):\n",
    "        print(f\"Metrics for class {label} (Class value: {i}):\")\n",
    "        print(f\"Specificity: {specificities[i]}\")\n",
    "        print(f\"FPR: {fprs[i]}\")\n",
    "        print(f\"Precision: {precisions[i]}\\n\")\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    accuracy = round(np.trace(cm) / np.sum(cm), 4)\n",
    "    print(f\"Overall accuracy: {accuracy}\")\n",
    "\n",
    "    # Calculate true values for each class for weighting purposes\n",
    "    true_values = np.sum(cm, axis=1)\n",
    "    total_true_values = np.sum(true_values)\n",
    "\n",
    "    # Calculate weighted average specificity and FPR\n",
    "    weighted_avg_spec = round(sum(specificities[i] * true_values[i] for i in range(3)) / total_true_values, 4)\n",
    "    weighted_avg_fpr = round(sum(fprs[i] * true_values[i] for i in range(3)) / total_true_values, 4)\n",
    "\n",
    "    # Calculate macro average specificity and FPR\n",
    "    macro_avg_spec = round(np.mean(specificities), 4)\n",
    "    macro_avg_fpr = round(np.mean(fprs), 4)\n",
    "\n",
    "    print(f\"Weighted average specificity: {weighted_avg_spec}\")\n",
    "    print(f\"Weighted average FPR: {weighted_avg_fpr}\")\n",
    "    print(f\"Macro average specificity: {macro_avg_spec}\")\n",
    "    print(f\"Macro average FPR: {macro_avg_fpr}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba67264a-51f7-4d1c-b4bd-5f97f29a3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['cleaned_tweets'], df['target'], test_size=0.3, random_state=5)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=5)\n",
    "\n",
    "# Convert the label series to lists\n",
    "train_labels = train_labels.tolist()\n",
    "val_labels = val_labels.tolist()\n",
    "test_labels = test_labels.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c735aff4-ac37-45a6-980b-c9030ad2bbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load BERTweet tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n",
    "\n",
    "# Tokenize the data\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80b32c8f-d4fc-4bb0-b166-f925f7fd42bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc}\n",
    "\n",
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TweetDataset(train_encodings, train_labels)\n",
    "val_dataset = TweetDataset(val_encodings, val_labels)\n",
    "test_dataset = TweetDataset(test_encodings, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4d7d1df-7d7c-4d21-abf5-ce0a92286345",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 08:44:58,656] A new study created in memory with name: no-name-b88c9166-a738-4608-9aea-bf0cb51eac13\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1190' max='1190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1190/1190 11:19, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.107000</td>\n",
       "      <td>1.060747</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.078600</td>\n",
       "      <td>1.022240</td>\n",
       "      <td>0.465931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 08:56:38,056] Trial 0 finished with value: 0.48676470588235293 and parameters: {'learning_rate': 4.2685479870621735e-06, 'num_train_epochs': 2, 'per_device_train_batch_size': 32, 'weight_decay': 0.025514431455395215, 'hidden_dropout_prob': 0.2677637968911644}. Best is trial 0 with value: 0.48676470588235293.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2975' max='2975' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2975/2975 28:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.123600</td>\n",
       "      <td>1.086257</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.114000</td>\n",
       "      <td>1.115927</td>\n",
       "      <td>0.307353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.108900</td>\n",
       "      <td>1.086869</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.107500</td>\n",
       "      <td>1.085181</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.103100</td>\n",
       "      <td>1.086632</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 09:25:14,224] Trial 1 finished with value: 0.41151960784313724 and parameters: {'learning_rate': 5.490865266488238e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 32, 'weight_decay': 0.02445977332515985, 'hidden_dropout_prob': 0.35238118944019825}. Best is trial 0 with value: 0.48676470588235293.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1190' max='1190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1190/1190 11:07, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.078300</td>\n",
       "      <td>1.003651</td>\n",
       "      <td>0.486520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.990500</td>\n",
       "      <td>0.954853</td>\n",
       "      <td>0.515196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 09:36:41,469] Trial 2 finished with value: 0.5470588235294118 and parameters: {'learning_rate': 5.148355491743566e-06, 'num_train_epochs': 2, 'per_device_train_batch_size': 32, 'weight_decay': 0.022537684712995467, 'hidden_dropout_prob': 0.1889836372458741}. Best is trial 2 with value: 0.5470588235294118.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3570' max='3570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3570/3570 22:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.112900</td>\n",
       "      <td>1.075870</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.106500</td>\n",
       "      <td>1.048477</td>\n",
       "      <td>0.429412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.040600</td>\n",
       "      <td>0.974476</td>\n",
       "      <td>0.506618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.989500</td>\n",
       "      <td>0.913667</td>\n",
       "      <td>0.551961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.946500</td>\n",
       "      <td>0.912280</td>\n",
       "      <td>0.565196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.938600</td>\n",
       "      <td>0.893218</td>\n",
       "      <td>0.577451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.921300</td>\n",
       "      <td>0.897905</td>\n",
       "      <td>0.575980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 09:59:38,621] Trial 3 finished with value: 0.5519607843137255 and parameters: {'learning_rate': 7.045704466960934e-06, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.07534475655835057, 'hidden_dropout_prob': 0.33897880545276554}. Best is trial 3 with value: 0.5519607843137255.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2380' max='2380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2380/2380 22:15, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.126800</td>\n",
       "      <td>1.073715</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.992100</td>\n",
       "      <td>0.905580</td>\n",
       "      <td>0.578922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.864200</td>\n",
       "      <td>0.862845</td>\n",
       "      <td>0.618137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.817486</td>\n",
       "      <td>0.660539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 10:22:13,689] Trial 4 finished with value: 0.6605392156862745 and parameters: {'learning_rate': 2.5735686741688906e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.029152785611750432, 'hidden_dropout_prob': 0.4294205774969602}. Best is trial 4 with value: 0.6605392156862745.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1190' max='1190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1190/1190 11:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.124900</td>\n",
       "      <td>1.063130</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.968200</td>\n",
       "      <td>0.858868</td>\n",
       "      <td>0.608578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 10:33:39,793] Trial 5 finished with value: 0.6115196078431373 and parameters: {'learning_rate': 3.471903018586616e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 32, 'weight_decay': 0.02880778334772445, 'hidden_dropout_prob': 0.3728739712774348}. Best is trial 4 with value: 0.6605392156862745.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5950' max='5950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5950/5950 37:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.095200</td>\n",
       "      <td>1.074592</td>\n",
       "      <td>0.419363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.009300</td>\n",
       "      <td>0.945520</td>\n",
       "      <td>0.540931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.946800</td>\n",
       "      <td>0.875688</td>\n",
       "      <td>0.590441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.898600</td>\n",
       "      <td>0.866408</td>\n",
       "      <td>0.574755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.861000</td>\n",
       "      <td>0.862718</td>\n",
       "      <td>0.591667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.841100</td>\n",
       "      <td>0.830579</td>\n",
       "      <td>0.622059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.832700</td>\n",
       "      <td>0.804765</td>\n",
       "      <td>0.631618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.804600</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.627206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.798600</td>\n",
       "      <td>0.804724</td>\n",
       "      <td>0.637255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.759700</td>\n",
       "      <td>0.798322</td>\n",
       "      <td>0.642892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.759600</td>\n",
       "      <td>0.796896</td>\n",
       "      <td>0.648529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 11:11:33,234] Trial 6 finished with value: 0.6272058823529412 and parameters: {'learning_rate': 5.269649677555653e-06, 'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'weight_decay': 0.06273157359656985, 'hidden_dropout_prob': 0.16072446223538905}. Best is trial 4 with value: 0.6605392156862745.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2380' max='2380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2380/2380 14:55, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.121400</td>\n",
       "      <td>1.076199</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.112300</td>\n",
       "      <td>1.052012</td>\n",
       "      <td>0.423039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.061600</td>\n",
       "      <td>1.026009</td>\n",
       "      <td>0.480882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.008900</td>\n",
       "      <td>0.939504</td>\n",
       "      <td>0.536520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 11:26:48,301] Trial 7 finished with value: 0.5365196078431372 and parameters: {'learning_rate': 8.013450432975328e-06, 'num_train_epochs': 2, 'per_device_train_batch_size': 16, 'weight_decay': 0.06637270567489365, 'hidden_dropout_prob': 0.359627421131697}. Best is trial 4 with value: 0.6605392156862745.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2380' max='2380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2380/2380 22:15, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.055400</td>\n",
       "      <td>0.944227</td>\n",
       "      <td>0.521078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.929900</td>\n",
       "      <td>0.885826</td>\n",
       "      <td>0.573039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.868900</td>\n",
       "      <td>0.841610</td>\n",
       "      <td>0.611275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.846100</td>\n",
       "      <td>0.826742</td>\n",
       "      <td>0.618382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 11:49:23,144] Trial 8 finished with value: 0.6183823529411765 and parameters: {'learning_rate': 5.950736549234946e-06, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.026875548573611574, 'hidden_dropout_prob': 0.16160563837731026}. Best is trial 4 with value: 0.6605392156862745.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4760' max='4760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4760/4760 30:07, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.094100</td>\n",
       "      <td>1.034874</td>\n",
       "      <td>0.474755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.941700</td>\n",
       "      <td>0.861404</td>\n",
       "      <td>0.594363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.874900</td>\n",
       "      <td>0.865712</td>\n",
       "      <td>0.608824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.810200</td>\n",
       "      <td>0.837885</td>\n",
       "      <td>0.637745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.775300</td>\n",
       "      <td>0.837193</td>\n",
       "      <td>0.636029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.719000</td>\n",
       "      <td>0.778501</td>\n",
       "      <td>0.667647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.726300</td>\n",
       "      <td>0.754920</td>\n",
       "      <td>0.667647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.671600</td>\n",
       "      <td>0.791425</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.666900</td>\n",
       "      <td>0.753302</td>\n",
       "      <td>0.684559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 12:19:50,539] Trial 9 finished with value: 0.675 and parameters: {'learning_rate': 1.4258824949416529e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.0007582354370409884, 'hidden_dropout_prob': 0.1891466987626471}. Best is trial 9 with value: 0.675.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1190' max='1190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1190/1190 07:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.089200</td>\n",
       "      <td>1.062438</td>\n",
       "      <td>0.425735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.076000</td>\n",
       "      <td>1.052836</td>\n",
       "      <td>0.418627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 12:27:36,912] Trial 10 finished with value: 0.43970588235294117 and parameters: {'learning_rate': 1.4299722304914938e-06, 'num_train_epochs': 1, 'per_device_train_batch_size': 16, 'weight_decay': 0.0024010422832600633, 'hidden_dropout_prob': 0.11025968682471946}. Best is trial 9 with value: 0.675.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4760' max='4760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4760/4760 30:07, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.141800</td>\n",
       "      <td>1.088462</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.135800</td>\n",
       "      <td>1.092189</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.131000</td>\n",
       "      <td>1.100269</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.120600</td>\n",
       "      <td>1.095031</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.112000</td>\n",
       "      <td>1.096226</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.063300</td>\n",
       "      <td>0.928953</td>\n",
       "      <td>0.546569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>0.914127</td>\n",
       "      <td>0.564951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.920300</td>\n",
       "      <td>0.903340</td>\n",
       "      <td>0.591912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.893600</td>\n",
       "      <td>0.913624</td>\n",
       "      <td>0.592402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 12:58:03,536] Trial 11 finished with value: 0.5919117647058824 and parameters: {'learning_rate': 2.3563954502152676e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.0003081631891954928, 'hidden_dropout_prob': 0.478306254732122}. Best is trial 9 with value: 0.675.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4760' max='4760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4760/4760 30:07, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.141700</td>\n",
       "      <td>1.084632</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.138400</td>\n",
       "      <td>1.092813</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.132700</td>\n",
       "      <td>1.095660</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.129400</td>\n",
       "      <td>1.095289</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.117200</td>\n",
       "      <td>1.068901</td>\n",
       "      <td>0.417892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.051700</td>\n",
       "      <td>1.050243</td>\n",
       "      <td>0.499510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.984600</td>\n",
       "      <td>0.948833</td>\n",
       "      <td>0.530392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.949100</td>\n",
       "      <td>0.938315</td>\n",
       "      <td>0.570098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.927100</td>\n",
       "      <td>0.921950</td>\n",
       "      <td>0.572059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 13:28:30,362] Trial 12 finished with value: 0.5700980392156862 and parameters: {'learning_rate': 1.7893181411094835e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.0448763500066977, 'hidden_dropout_prob': 0.49421385891824593}. Best is trial 9 with value: 0.675.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1785' max='1785' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1785/1785 16:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.123100</td>\n",
       "      <td>1.085158</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.109300</td>\n",
       "      <td>1.118222</td>\n",
       "      <td>0.307353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.102200</td>\n",
       "      <td>1.089839</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 13:45:29,199] Trial 13 finished with value: 0.41151960784313724 and parameters: {'learning_rate': 8.62181741395325e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 32, 'weight_decay': 0.08724479727311571, 'hidden_dropout_prob': 0.2564706385747031}. Best is trial 9 with value: 0.675.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2380' max='2380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2380/2380 22:22, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.129100</td>\n",
       "      <td>1.082589</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.069300</td>\n",
       "      <td>0.936115</td>\n",
       "      <td>0.525980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.915179</td>\n",
       "      <td>0.564706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.898300</td>\n",
       "      <td>0.860734</td>\n",
       "      <td>0.611520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 14:08:11,456] Trial 14 finished with value: 0.6115196078431373 and parameters: {'learning_rate': 1.6764948155635213e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.011516480431068689, 'hidden_dropout_prob': 0.41701122347067493}. Best is trial 9 with value: 0.675.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5950' max='5950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5950/5950 38:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.115300</td>\n",
       "      <td>1.088517</td>\n",
       "      <td>0.431127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.026100</td>\n",
       "      <td>0.923527</td>\n",
       "      <td>0.554657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.873464</td>\n",
       "      <td>0.602696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.942552</td>\n",
       "      <td>0.579412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.829800</td>\n",
       "      <td>0.881045</td>\n",
       "      <td>0.618137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.797000</td>\n",
       "      <td>0.823866</td>\n",
       "      <td>0.642157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.789600</td>\n",
       "      <td>0.771209</td>\n",
       "      <td>0.662745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.746800</td>\n",
       "      <td>0.805524</td>\n",
       "      <td>0.664216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.741500</td>\n",
       "      <td>0.796366</td>\n",
       "      <td>0.667892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.712200</td>\n",
       "      <td>0.794304</td>\n",
       "      <td>0.671569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.701500</td>\n",
       "      <td>0.771926</td>\n",
       "      <td>0.675490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 14:46:48,547] Trial 15 finished with value: 0.6642156862745098 and parameters: {'learning_rate': 1.2704176048757585e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'weight_decay': 0.04490666352150642, 'hidden_dropout_prob': 0.2947346498510579}. Best is trial 9 with value: 0.675.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5950' max='5950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5950/5950 37:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.108300</td>\n",
       "      <td>1.050396</td>\n",
       "      <td>0.451716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.001600</td>\n",
       "      <td>0.884780</td>\n",
       "      <td>0.563480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.912100</td>\n",
       "      <td>0.853656</td>\n",
       "      <td>0.607108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.864700</td>\n",
       "      <td>0.886580</td>\n",
       "      <td>0.595098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.829100</td>\n",
       "      <td>0.834616</td>\n",
       "      <td>0.622059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.794600</td>\n",
       "      <td>0.789563</td>\n",
       "      <td>0.649265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.774200</td>\n",
       "      <td>0.781519</td>\n",
       "      <td>0.655392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.753200</td>\n",
       "      <td>0.794691</td>\n",
       "      <td>0.657598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.734500</td>\n",
       "      <td>0.779498</td>\n",
       "      <td>0.668137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.703900</td>\n",
       "      <td>0.787666</td>\n",
       "      <td>0.667402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>0.766181</td>\n",
       "      <td>0.669363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 15:24:47,829] Trial 16 finished with value: 0.6575980392156863 and parameters: {'learning_rate': 1.0675523747690886e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'weight_decay': 0.04498637219539812, 'hidden_dropout_prob': 0.2432812448311072}. Best is trial 9 with value: 0.675.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5950' max='5950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5950/5950 37:32, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.121600</td>\n",
       "      <td>1.084995</td>\n",
       "      <td>0.439216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.043000</td>\n",
       "      <td>0.902203</td>\n",
       "      <td>0.556373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.924100</td>\n",
       "      <td>0.878670</td>\n",
       "      <td>0.597059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.872400</td>\n",
       "      <td>0.856028</td>\n",
       "      <td>0.612745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.834500</td>\n",
       "      <td>0.823669</td>\n",
       "      <td>0.629902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.803200</td>\n",
       "      <td>0.795205</td>\n",
       "      <td>0.652941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.773900</td>\n",
       "      <td>0.787754</td>\n",
       "      <td>0.658088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.750800</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.661520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.739500</td>\n",
       "      <td>0.788660</td>\n",
       "      <td>0.670098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.804374</td>\n",
       "      <td>0.672304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.708000</td>\n",
       "      <td>0.773292</td>\n",
       "      <td>0.674265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 16:02:39,523] Trial 17 finished with value: 0.6615196078431372 and parameters: {'learning_rate': 1.2769435518734933e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'weight_decay': 0.09794719594424144, 'hidden_dropout_prob': 0.2952347956192623}. Best is trial 9 with value: 0.675.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3570' max='3570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3570/3570 22:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.120900</td>\n",
       "      <td>1.105022</td>\n",
       "      <td>0.307353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.112800</td>\n",
       "      <td>1.087096</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.105400</td>\n",
       "      <td>1.084818</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.105500</td>\n",
       "      <td>1.094313</td>\n",
       "      <td>0.307353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.096800</td>\n",
       "      <td>1.089456</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.100600</td>\n",
       "      <td>1.084745</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.092800</td>\n",
       "      <td>1.065834</td>\n",
       "      <td>0.421324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 16:25:38,686] Trial 18 finished with value: 0.3073529411764706 and parameters: {'learning_rate': 4.307502594262731e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.04090068586136282, 'hidden_dropout_prob': 0.21800574960826408}. Best is trial 9 with value: 0.675.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5950' max='5950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5950/5950 37:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.110800</td>\n",
       "      <td>1.101685</td>\n",
       "      <td>0.396814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.030900</td>\n",
       "      <td>0.898379</td>\n",
       "      <td>0.560049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.943400</td>\n",
       "      <td>0.867267</td>\n",
       "      <td>0.587990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.859270</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.840200</td>\n",
       "      <td>0.832431</td>\n",
       "      <td>0.628186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.812100</td>\n",
       "      <td>0.801202</td>\n",
       "      <td>0.652451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.783200</td>\n",
       "      <td>0.789096</td>\n",
       "      <td>0.658578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.762400</td>\n",
       "      <td>0.799770</td>\n",
       "      <td>0.655637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.757700</td>\n",
       "      <td>0.784449</td>\n",
       "      <td>0.665196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.725400</td>\n",
       "      <td>0.794973</td>\n",
       "      <td>0.666176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.719700</td>\n",
       "      <td>0.787078</td>\n",
       "      <td>0.671324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 17:03:31,672] Trial 19 finished with value: 0.6556372549019608 and parameters: {'learning_rate': 1.1852894446340523e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'weight_decay': 0.05605546855427107, 'hidden_dropout_prob': 0.3026901614002704}. Best is trial 9 with value: 0.675.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4760' max='4760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4760/4760 30:07, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.103400</td>\n",
       "      <td>1.063273</td>\n",
       "      <td>0.414216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.085100</td>\n",
       "      <td>1.027755</td>\n",
       "      <td>0.452941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.037400</td>\n",
       "      <td>1.012561</td>\n",
       "      <td>0.478922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.993600</td>\n",
       "      <td>0.946369</td>\n",
       "      <td>0.522304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>0.926814</td>\n",
       "      <td>0.542892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.911718</td>\n",
       "      <td>0.562255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.940800</td>\n",
       "      <td>0.897376</td>\n",
       "      <td>0.571324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.920100</td>\n",
       "      <td>0.907976</td>\n",
       "      <td>0.565441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.912300</td>\n",
       "      <td>0.886241</td>\n",
       "      <td>0.572304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 17:33:58,921] Trial 20 finished with value: 0.5654411764705882 and parameters: {'learning_rate': 2.786878855629246e-06, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.037608033539455715, 'hidden_dropout_prob': 0.21375549890092532}. Best is trial 9 with value: 0.675.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5950' max='5950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5950/5950 37:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.116500</td>\n",
       "      <td>1.085523</td>\n",
       "      <td>0.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.046700</td>\n",
       "      <td>0.962714</td>\n",
       "      <td>0.532108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.935400</td>\n",
       "      <td>0.861179</td>\n",
       "      <td>0.597059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.875200</td>\n",
       "      <td>0.845035</td>\n",
       "      <td>0.620588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.824200</td>\n",
       "      <td>0.827699</td>\n",
       "      <td>0.638235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.787600</td>\n",
       "      <td>0.820941</td>\n",
       "      <td>0.643382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.777400</td>\n",
       "      <td>0.791281</td>\n",
       "      <td>0.661029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.739300</td>\n",
       "      <td>0.798110</td>\n",
       "      <td>0.672304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.724400</td>\n",
       "      <td>0.790697</td>\n",
       "      <td>0.672794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.702100</td>\n",
       "      <td>0.795673</td>\n",
       "      <td>0.671078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.690700</td>\n",
       "      <td>0.785800</td>\n",
       "      <td>0.677941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 18:11:55,827] Trial 21 finished with value: 0.6723039215686275 and parameters: {'learning_rate': 1.3735918986088733e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'weight_decay': 0.09583238389119685, 'hidden_dropout_prob': 0.29453089919014325}. Best is trial 9 with value: 0.675.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5950' max='5950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5950/5950 37:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.122800</td>\n",
       "      <td>1.089867</td>\n",
       "      <td>0.425735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.032200</td>\n",
       "      <td>0.890825</td>\n",
       "      <td>0.567892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.900100</td>\n",
       "      <td>0.881156</td>\n",
       "      <td>0.593873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.841600</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.626961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.802400</td>\n",
       "      <td>0.820464</td>\n",
       "      <td>0.655392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.763900</td>\n",
       "      <td>0.795308</td>\n",
       "      <td>0.668137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.738600</td>\n",
       "      <td>0.778073</td>\n",
       "      <td>0.668627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.706400</td>\n",
       "      <td>0.797371</td>\n",
       "      <td>0.678676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.700600</td>\n",
       "      <td>0.795360</td>\n",
       "      <td>0.684069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.663100</td>\n",
       "      <td>0.801307</td>\n",
       "      <td>0.683578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.664900</td>\n",
       "      <td>0.763556</td>\n",
       "      <td>0.687010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 18:49:52,999] Trial 22 finished with value: 0.6786764705882353 and parameters: {'learning_rate': 1.6537240709672837e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'weight_decay': 0.05519068137831055, 'hidden_dropout_prob': 0.2954972146163285}. Best is trial 22 with value: 0.6786764705882353.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5950' max='5950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5950/5950 37:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.114000</td>\n",
       "      <td>1.068572</td>\n",
       "      <td>0.408088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.965200</td>\n",
       "      <td>0.901153</td>\n",
       "      <td>0.565686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.859200</td>\n",
       "      <td>0.875222</td>\n",
       "      <td>0.624020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.800300</td>\n",
       "      <td>0.835434</td>\n",
       "      <td>0.640686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.767300</td>\n",
       "      <td>0.816690</td>\n",
       "      <td>0.670098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.719300</td>\n",
       "      <td>0.798024</td>\n",
       "      <td>0.678431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.701300</td>\n",
       "      <td>0.751871</td>\n",
       "      <td>0.687745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.656200</td>\n",
       "      <td>0.793437</td>\n",
       "      <td>0.687010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.648700</td>\n",
       "      <td>0.789123</td>\n",
       "      <td>0.694118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.611300</td>\n",
       "      <td>0.801318</td>\n",
       "      <td>0.694118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.613700</td>\n",
       "      <td>0.753855</td>\n",
       "      <td>0.690441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 19:27:51,095] Trial 23 finished with value: 0.6870098039215686 and parameters: {'learning_rate': 2.0503481577550024e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'weight_decay': 0.05398598842396098, 'hidden_dropout_prob': 0.2701657792487996}. Best is trial 23 with value: 0.6870098039215686.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4760' max='4760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4760/4760 30:12, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.104400</td>\n",
       "      <td>0.976137</td>\n",
       "      <td>0.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.933400</td>\n",
       "      <td>0.842045</td>\n",
       "      <td>0.608824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.839300</td>\n",
       "      <td>0.812956</td>\n",
       "      <td>0.646324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.774600</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.742300</td>\n",
       "      <td>0.789214</td>\n",
       "      <td>0.676716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693700</td>\n",
       "      <td>0.772895</td>\n",
       "      <td>0.680147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.679700</td>\n",
       "      <td>0.735733</td>\n",
       "      <td>0.691422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.633800</td>\n",
       "      <td>0.772855</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.624900</td>\n",
       "      <td>0.760586</td>\n",
       "      <td>0.696569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 19:58:22,892] Trial 24 finished with value: 0.6911764705882353 and parameters: {'learning_rate': 2.1708927078749916e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.05339731070034126, 'hidden_dropout_prob': 0.23357225673007237}. Best is trial 24 with value: 0.6911764705882353.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5950' max='5950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5950/5950 37:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.113400</td>\n",
       "      <td>1.090996</td>\n",
       "      <td>0.455147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.994800</td>\n",
       "      <td>0.891784</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.857100</td>\n",
       "      <td>0.852095</td>\n",
       "      <td>0.623284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.792400</td>\n",
       "      <td>0.845504</td>\n",
       "      <td>0.661029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.745500</td>\n",
       "      <td>0.813428</td>\n",
       "      <td>0.670833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.694300</td>\n",
       "      <td>0.767788</td>\n",
       "      <td>0.679167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.675300</td>\n",
       "      <td>0.738092</td>\n",
       "      <td>0.689461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.623300</td>\n",
       "      <td>0.786489</td>\n",
       "      <td>0.695833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.617700</td>\n",
       "      <td>0.739954</td>\n",
       "      <td>0.702696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.589700</td>\n",
       "      <td>0.764951</td>\n",
       "      <td>0.699510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.566400</td>\n",
       "      <td>0.770400</td>\n",
       "      <td>0.694853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 20:36:25,413] Trial 25 finished with value: 0.6958333333333333 and parameters: {'learning_rate': 2.3392805942469323e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'weight_decay': 0.05440328333079075, 'hidden_dropout_prob': 0.25063965427570883}. Best is trial 25 with value: 0.6958333333333333.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3570' max='3570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3570/3570 22:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.101100</td>\n",
       "      <td>0.939388</td>\n",
       "      <td>0.549510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.929900</td>\n",
       "      <td>0.831989</td>\n",
       "      <td>0.613235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.830400</td>\n",
       "      <td>0.819403</td>\n",
       "      <td>0.650735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.765300</td>\n",
       "      <td>0.806299</td>\n",
       "      <td>0.660539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.728600</td>\n",
       "      <td>0.788858</td>\n",
       "      <td>0.683578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.679400</td>\n",
       "      <td>0.762247</td>\n",
       "      <td>0.683088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.746226</td>\n",
       "      <td>0.687745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 20:59:30,122] Trial 26 finished with value: 0.6605392156862745 and parameters: {'learning_rate': 2.5561383958316996e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.053183390887766045, 'hidden_dropout_prob': 0.23648739530159296}. Best is trial 25 with value: 0.6958333333333333.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4760' max='4760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4760/4760 30:14, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.122300</td>\n",
       "      <td>1.094521</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.115200</td>\n",
       "      <td>1.081604</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.998300</td>\n",
       "      <td>0.889639</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.850800</td>\n",
       "      <td>0.861592</td>\n",
       "      <td>0.638480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.774400</td>\n",
       "      <td>0.804812</td>\n",
       "      <td>0.662990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.710500</td>\n",
       "      <td>0.774262</td>\n",
       "      <td>0.682353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.686700</td>\n",
       "      <td>0.751814</td>\n",
       "      <td>0.687255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.628800</td>\n",
       "      <td>0.743997</td>\n",
       "      <td>0.690441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.630700</td>\n",
       "      <td>0.745715</td>\n",
       "      <td>0.694608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 21:30:04,115] Trial 27 finished with value: 0.6904411764705882 and parameters: {'learning_rate': 3.39303862927485e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.06247321203811164, 'hidden_dropout_prob': 0.2641258241576701}. Best is trial 25 with value: 0.6958333333333333.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4760' max='4760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4760/4760 30:15, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.117200</td>\n",
       "      <td>1.094247</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.116200</td>\n",
       "      <td>1.092564</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.107500</td>\n",
       "      <td>1.085361</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.109900</td>\n",
       "      <td>1.098210</td>\n",
       "      <td>0.307353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.099700</td>\n",
       "      <td>1.089599</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.104600</td>\n",
       "      <td>1.088793</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.101300</td>\n",
       "      <td>1.085105</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.095400</td>\n",
       "      <td>1.092031</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.101200</td>\n",
       "      <td>1.088760</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 22:00:39,227] Trial 28 finished with value: 0.41151960784313724 and parameters: {'learning_rate': 3.2606652502590356e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.06643260336808651, 'hidden_dropout_prob': 0.23550779530947227}. Best is trial 25 with value: 0.6958333333333333.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3570' max='3570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3570/3570 22:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.130800</td>\n",
       "      <td>1.095241</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.121400</td>\n",
       "      <td>1.093589</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.114300</td>\n",
       "      <td>1.087865</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.115800</td>\n",
       "      <td>1.096083</td>\n",
       "      <td>0.307353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.103000</td>\n",
       "      <td>1.090024</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.108600</td>\n",
       "      <td>1.084969</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.103200</td>\n",
       "      <td>1.085495</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 22:23:46,157] Trial 29 finished with value: 0.3073529411764706 and parameters: {'learning_rate': 5.8494429031818955e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.07578928907085548, 'hidden_dropout_prob': 0.3202978927913171}. Best is trial 25 with value: 0.6958333333333333.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1190' max='1190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1190/1190 07:31, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.120500</td>\n",
       "      <td>1.083431</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.066600</td>\n",
       "      <td>0.924167</td>\n",
       "      <td>0.525735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 22:31:36,530] Trial 30 finished with value: 0.5553921568627451 and parameters: {'learning_rate': 3.356901419578884e-05, 'num_train_epochs': 1, 'per_device_train_batch_size': 16, 'weight_decay': 0.06144739533254949, 'hidden_dropout_prob': 0.26606319295395914}. Best is trial 25 with value: 0.6958333333333333.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5950' max='5950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5950/5950 37:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.116300</td>\n",
       "      <td>1.118756</td>\n",
       "      <td>0.376716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.990900</td>\n",
       "      <td>0.862522</td>\n",
       "      <td>0.588725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.882400</td>\n",
       "      <td>0.825938</td>\n",
       "      <td>0.635539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.804300</td>\n",
       "      <td>0.832520</td>\n",
       "      <td>0.650735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>0.786416</td>\n",
       "      <td>0.667157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.719700</td>\n",
       "      <td>0.788610</td>\n",
       "      <td>0.668137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.695400</td>\n",
       "      <td>0.737807</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.656900</td>\n",
       "      <td>0.792386</td>\n",
       "      <td>0.688725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.647000</td>\n",
       "      <td>0.769903</td>\n",
       "      <td>0.694853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.613800</td>\n",
       "      <td>0.764813</td>\n",
       "      <td>0.693382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.770717</td>\n",
       "      <td>0.684314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 23:09:37,976] Trial 31 finished with value: 0.6887254901960784 and parameters: {'learning_rate': 2.1055129751802792e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'weight_decay': 0.050230869632403335, 'hidden_dropout_prob': 0.270165767574648}. Best is trial 25 with value: 0.6958333333333333.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4760' max='4760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4760/4760 30:18, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.112000</td>\n",
       "      <td>0.998350</td>\n",
       "      <td>0.476471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.953900</td>\n",
       "      <td>0.846914</td>\n",
       "      <td>0.608333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.847400</td>\n",
       "      <td>0.870467</td>\n",
       "      <td>0.629167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.776800</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.743500</td>\n",
       "      <td>0.794861</td>\n",
       "      <td>0.682108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.768784</td>\n",
       "      <td>0.672059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.676200</td>\n",
       "      <td>0.748615</td>\n",
       "      <td>0.689706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.629000</td>\n",
       "      <td>0.787858</td>\n",
       "      <td>0.693627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.618900</td>\n",
       "      <td>0.765111</td>\n",
       "      <td>0.695588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 23:40:15,999] Trial 32 finished with value: 0.6936274509803921 and parameters: {'learning_rate': 2.499047461230651e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.04982293409388147, 'hidden_dropout_prob': 0.266674398246229}. Best is trial 25 with value: 0.6958333333333333.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4760' max='4760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4760/4760 30:18, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.124400</td>\n",
       "      <td>1.102312</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.118200</td>\n",
       "      <td>1.087094</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.113100</td>\n",
       "      <td>1.087583</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.113800</td>\n",
       "      <td>1.104719</td>\n",
       "      <td>0.281127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.105100</td>\n",
       "      <td>1.089219</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.104400</td>\n",
       "      <td>1.088668</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.102000</td>\n",
       "      <td>1.085440</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.100800</td>\n",
       "      <td>1.094869</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.103100</td>\n",
       "      <td>1.089235</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 00:10:54,190] Trial 33 finished with value: 0.41151960784313724 and parameters: {'learning_rate': 5.1959163688559535e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.058835124627198976, 'hidden_dropout_prob': 0.26865099064543074}. Best is trial 25 with value: 0.6958333333333333.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3570' max='3570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3570/3570 22:49, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.115000</td>\n",
       "      <td>1.079236</td>\n",
       "      <td>0.469608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.856972</td>\n",
       "      <td>0.598284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.823500</td>\n",
       "      <td>0.805922</td>\n",
       "      <td>0.649265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.756800</td>\n",
       "      <td>0.808485</td>\n",
       "      <td>0.668627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.715400</td>\n",
       "      <td>0.774753</td>\n",
       "      <td>0.682108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.666500</td>\n",
       "      <td>0.742863</td>\n",
       "      <td>0.684559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.638300</td>\n",
       "      <td>0.742638</td>\n",
       "      <td>0.687745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 00:34:03,392] Trial 34 finished with value: 0.6686274509803921 and parameters: {'learning_rate': 2.879664634437225e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.050107754353179323, 'hidden_dropout_prob': 0.21937432053682926}. Best is trial 25 with value: 0.6958333333333333.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4760' max='4760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4760/4760 30:19, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.125800</td>\n",
       "      <td>1.089994</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.121500</td>\n",
       "      <td>1.088631</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.114500</td>\n",
       "      <td>1.087230</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.110700</td>\n",
       "      <td>1.105171</td>\n",
       "      <td>0.307353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.104800</td>\n",
       "      <td>1.090660</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.107000</td>\n",
       "      <td>1.088358</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.103000</td>\n",
       "      <td>1.085474</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.100100</td>\n",
       "      <td>1.094083</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.104700</td>\n",
       "      <td>1.090060</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 01:04:42,741] Trial 35 finished with value: 0.41151960784313724 and parameters: {'learning_rate': 4.13244735101072e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.03583900650933111, 'hidden_dropout_prob': 0.31731643206348203}. Best is trial 25 with value: 0.6958333333333333.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2380' max='2380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2380/2380 22:20, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.053400</td>\n",
       "      <td>0.885335</td>\n",
       "      <td>0.564216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.844100</td>\n",
       "      <td>0.836230</td>\n",
       "      <td>0.621569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.747600</td>\n",
       "      <td>0.790039</td>\n",
       "      <td>0.663480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.700300</td>\n",
       "      <td>0.777211</td>\n",
       "      <td>0.676225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 01:27:23,405] Trial 36 finished with value: 0.6762254901960785 and parameters: {'learning_rate': 2.4927701080092692e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.07308784597306114, 'hidden_dropout_prob': 0.25583734112880224}. Best is trial 25 with value: 0.6958333333333333.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3570' max='3570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3570/3570 23:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.115100</td>\n",
       "      <td>1.072094</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.079100</td>\n",
       "      <td>0.978081</td>\n",
       "      <td>0.519853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.994900</td>\n",
       "      <td>0.923837</td>\n",
       "      <td>0.545588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.943400</td>\n",
       "      <td>0.921809</td>\n",
       "      <td>0.569363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.901800</td>\n",
       "      <td>0.870911</td>\n",
       "      <td>0.595833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.859023</td>\n",
       "      <td>0.603676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.883800</td>\n",
       "      <td>0.851001</td>\n",
       "      <td>0.609559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 01:50:48,073] Trial 37 finished with value: 0.5693627450980392 and parameters: {'learning_rate': 9.599147733729168e-06, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.04833448905130969, 'hidden_dropout_prob': 0.3358555281916723}. Best is trial 25 with value: 0.6958333333333333.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4760' max='4760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4760/4760 31:17, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.111100</td>\n",
       "      <td>1.126760</td>\n",
       "      <td>0.392892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.950300</td>\n",
       "      <td>0.844383</td>\n",
       "      <td>0.615931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.815500</td>\n",
       "      <td>0.822646</td>\n",
       "      <td>0.629902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.749700</td>\n",
       "      <td>0.797175</td>\n",
       "      <td>0.668873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.708600</td>\n",
       "      <td>0.786303</td>\n",
       "      <td>0.686275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.638800</td>\n",
       "      <td>0.798365</td>\n",
       "      <td>0.669608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.636800</td>\n",
       "      <td>0.731554</td>\n",
       "      <td>0.691422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.578600</td>\n",
       "      <td>0.743610</td>\n",
       "      <td>0.698039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.574500</td>\n",
       "      <td>0.753357</td>\n",
       "      <td>0.696569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 02:22:25,512] Trial 38 finished with value: 0.6980392156862745 and parameters: {'learning_rate': 2.8337878528723636e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.05919640226444356, 'hidden_dropout_prob': 0.20334239998464515}. Best is trial 38 with value: 0.6980392156862745.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1190' max='1190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1190/1190 11:11, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.027500</td>\n",
       "      <td>0.875171</td>\n",
       "      <td>0.573039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.858500</td>\n",
       "      <td>0.825754</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 02:33:56,353] Trial 39 finished with value: 0.6284313725490196 and parameters: {'learning_rate': 1.715720188067891e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 32, 'weight_decay': 0.036020376066192086, 'hidden_dropout_prob': 0.17943968163444063}. Best is trial 38 with value: 0.6980392156862745.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4760' max='4760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4760/4760 30:36, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.098400</td>\n",
       "      <td>0.958885</td>\n",
       "      <td>0.504657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.926400</td>\n",
       "      <td>0.844514</td>\n",
       "      <td>0.609069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.843100</td>\n",
       "      <td>0.839987</td>\n",
       "      <td>0.621078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.777100</td>\n",
       "      <td>0.787007</td>\n",
       "      <td>0.671814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.728800</td>\n",
       "      <td>0.807409</td>\n",
       "      <td>0.679412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.679300</td>\n",
       "      <td>0.756232</td>\n",
       "      <td>0.695098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.675100</td>\n",
       "      <td>0.739633</td>\n",
       "      <td>0.694853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.626300</td>\n",
       "      <td>0.762541</td>\n",
       "      <td>0.697549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.618500</td>\n",
       "      <td>0.739146</td>\n",
       "      <td>0.703186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 03:04:52,404] Trial 40 finished with value: 0.6975490196078431 and parameters: {'learning_rate': 2.045732501512822e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.05765626739462766, 'hidden_dropout_prob': 0.2054775353596721}. Best is trial 38 with value: 0.6980392156862745.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4760' max='4760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4760/4760 30:37, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.098100</td>\n",
       "      <td>0.955920</td>\n",
       "      <td>0.525490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.870433</td>\n",
       "      <td>0.590686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.829300</td>\n",
       "      <td>0.795134</td>\n",
       "      <td>0.651961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.767800</td>\n",
       "      <td>0.836029</td>\n",
       "      <td>0.663235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.728900</td>\n",
       "      <td>0.765246</td>\n",
       "      <td>0.682108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.673400</td>\n",
       "      <td>0.757304</td>\n",
       "      <td>0.680147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.728463</td>\n",
       "      <td>0.696078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.613000</td>\n",
       "      <td>0.762987</td>\n",
       "      <td>0.693873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.601400</td>\n",
       "      <td>0.738950</td>\n",
       "      <td>0.700980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 03:35:50,142] Trial 41 finished with value: 0.6938725490196078 and parameters: {'learning_rate': 2.1223637558829393e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.05723503403536146, 'hidden_dropout_prob': 0.20173158748114328}. Best is trial 38 with value: 0.6980392156862745.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4760' max='4760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4760/4760 30:44, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.110900</td>\n",
       "      <td>1.140913</td>\n",
       "      <td>0.310049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.113500</td>\n",
       "      <td>1.085816</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.107800</td>\n",
       "      <td>1.085438</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.074400</td>\n",
       "      <td>1.034368</td>\n",
       "      <td>0.513235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.888900</td>\n",
       "      <td>0.881591</td>\n",
       "      <td>0.571814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.812400</td>\n",
       "      <td>0.807301</td>\n",
       "      <td>0.635049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.768800</td>\n",
       "      <td>0.759385</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.788052</td>\n",
       "      <td>0.668873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.673400</td>\n",
       "      <td>0.753054</td>\n",
       "      <td>0.678186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 04:06:54,405] Trial 42 finished with value: 0.6688725490196078 and parameters: {'learning_rate': 2.6767069056813815e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.05910646440252606, 'hidden_dropout_prob': 0.20250095588811517}. Best is trial 38 with value: 0.6980392156862745.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4760' max='4760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4760/4760 30:50, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.097600</td>\n",
       "      <td>0.971662</td>\n",
       "      <td>0.500735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.927700</td>\n",
       "      <td>0.852662</td>\n",
       "      <td>0.600735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.827600</td>\n",
       "      <td>0.795282</td>\n",
       "      <td>0.658578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.768500</td>\n",
       "      <td>0.826962</td>\n",
       "      <td>0.666422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.728400</td>\n",
       "      <td>0.768817</td>\n",
       "      <td>0.684314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.670800</td>\n",
       "      <td>0.764534</td>\n",
       "      <td>0.674020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.660200</td>\n",
       "      <td>0.729625</td>\n",
       "      <td>0.697549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.606600</td>\n",
       "      <td>0.776768</td>\n",
       "      <td>0.693382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.599400</td>\n",
       "      <td>0.740804</td>\n",
       "      <td>0.701225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 04:38:05,116] Trial 43 finished with value: 0.6933823529411764 and parameters: {'learning_rate': 2.1444450586982785e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.06577865167093935, 'hidden_dropout_prob': 0.1980259340117487}. Best is trial 38 with value: 0.6980392156862745.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3570' max='3570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3570/3570 23:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.086300</td>\n",
       "      <td>1.044467</td>\n",
       "      <td>0.453922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.972200</td>\n",
       "      <td>0.912362</td>\n",
       "      <td>0.556127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.904700</td>\n",
       "      <td>0.849774</td>\n",
       "      <td>0.604412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.859500</td>\n",
       "      <td>0.847264</td>\n",
       "      <td>0.608088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.816700</td>\n",
       "      <td>0.815938</td>\n",
       "      <td>0.631127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.790100</td>\n",
       "      <td>0.814096</td>\n",
       "      <td>0.636275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.777200</td>\n",
       "      <td>0.800569</td>\n",
       "      <td>0.639951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 05:01:28,401] Trial 44 finished with value: 0.6080882352941176 and parameters: {'learning_rate': 9.51766687486612e-06, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.06896832769081736, 'hidden_dropout_prob': 0.17266929351255877}. Best is trial 38 with value: 0.6980392156862745.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5950' max='5950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5950/5950 38:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.105900</td>\n",
       "      <td>1.072201</td>\n",
       "      <td>0.456373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.911091</td>\n",
       "      <td>0.546814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.866300</td>\n",
       "      <td>0.823139</td>\n",
       "      <td>0.634069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.782700</td>\n",
       "      <td>0.768799</td>\n",
       "      <td>0.671569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.718500</td>\n",
       "      <td>0.779346</td>\n",
       "      <td>0.685784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.650700</td>\n",
       "      <td>0.759081</td>\n",
       "      <td>0.680147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.646200</td>\n",
       "      <td>0.721991</td>\n",
       "      <td>0.697059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.573400</td>\n",
       "      <td>0.775425</td>\n",
       "      <td>0.691667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.572300</td>\n",
       "      <td>0.735674</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.528700</td>\n",
       "      <td>0.785332</td>\n",
       "      <td>0.692647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>0.782477</td>\n",
       "      <td>0.690441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 05:40:30,336] Trial 45 finished with value: 0.6916666666666667 and parameters: {'learning_rate': 3.0338285316432447e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'weight_decay': 0.059583015618635424, 'hidden_dropout_prob': 0.14514206763753768}. Best is trial 38 with value: 0.6980392156862745.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2380' max='2380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2380/2380 22:48, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.035500</td>\n",
       "      <td>0.870252</td>\n",
       "      <td>0.576716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.863600</td>\n",
       "      <td>0.870510</td>\n",
       "      <td>0.580882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.781100</td>\n",
       "      <td>0.791989</td>\n",
       "      <td>0.649755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.747300</td>\n",
       "      <td>0.774551</td>\n",
       "      <td>0.669118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 06:03:39,942] Trial 46 finished with value: 0.6691176470588235 and parameters: {'learning_rate': 1.580762527843832e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.04846215594456003, 'hidden_dropout_prob': 0.2029324061406485}. Best is trial 38 with value: 0.6980392156862745.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3570' max='3570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3570/3570 23:49, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.120500</td>\n",
       "      <td>1.098344</td>\n",
       "      <td>0.412255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.113800</td>\n",
       "      <td>1.087371</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.105100</td>\n",
       "      <td>1.085600</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.104900</td>\n",
       "      <td>1.097995</td>\n",
       "      <td>0.307353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.008400</td>\n",
       "      <td>0.966732</td>\n",
       "      <td>0.528922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.915600</td>\n",
       "      <td>0.902803</td>\n",
       "      <td>0.558333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.887800</td>\n",
       "      <td>0.874352</td>\n",
       "      <td>0.565441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 06:27:49,765] Trial 47 finished with value: 0.3073529411764706 and parameters: {'learning_rate': 4.0695785480969936e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.057864185957756636, 'hidden_dropout_prob': 0.18146581772050693}. Best is trial 38 with value: 0.6980392156862745.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4760' max='4760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4760/4760 31:13, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.074500</td>\n",
       "      <td>0.956158</td>\n",
       "      <td>0.535294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.911900</td>\n",
       "      <td>0.827628</td>\n",
       "      <td>0.625245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.822800</td>\n",
       "      <td>0.833347</td>\n",
       "      <td>0.632598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.754600</td>\n",
       "      <td>0.771261</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.712800</td>\n",
       "      <td>0.763030</td>\n",
       "      <td>0.676716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.657600</td>\n",
       "      <td>0.741773</td>\n",
       "      <td>0.684314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.649400</td>\n",
       "      <td>0.731554</td>\n",
       "      <td>0.683578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.596500</td>\n",
       "      <td>0.751970</td>\n",
       "      <td>0.693382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.595100</td>\n",
       "      <td>0.730478</td>\n",
       "      <td>0.697549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 06:59:22,869] Trial 48 finished with value: 0.6933823529411764 and parameters: {'learning_rate': 1.940217962068367e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.06386101920748029, 'hidden_dropout_prob': 0.15085665547882618}. Best is trial 38 with value: 0.6980392156862745.\n",
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5950' max='5950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5950/5950 39:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.104800</td>\n",
       "      <td>1.059057</td>\n",
       "      <td>0.429167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.971300</td>\n",
       "      <td>0.869616</td>\n",
       "      <td>0.586275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.877700</td>\n",
       "      <td>0.836596</td>\n",
       "      <td>0.618382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.817600</td>\n",
       "      <td>0.840564</td>\n",
       "      <td>0.641912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.777200</td>\n",
       "      <td>0.798259</td>\n",
       "      <td>0.662745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.730500</td>\n",
       "      <td>0.782464</td>\n",
       "      <td>0.669363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.718200</td>\n",
       "      <td>0.751267</td>\n",
       "      <td>0.679902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.678500</td>\n",
       "      <td>0.775752</td>\n",
       "      <td>0.685784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.664600</td>\n",
       "      <td>0.760081</td>\n",
       "      <td>0.693382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.642300</td>\n",
       "      <td>0.760560</td>\n",
       "      <td>0.688235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.624500</td>\n",
       "      <td>0.759130</td>\n",
       "      <td>0.692157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 07:39:24,991] Trial 49 finished with value: 0.6857843137254902 and parameters: {'learning_rate': 1.4796801385849105e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'weight_decay': 0.07129542840654016, 'hidden_dropout_prob': 0.22307006705353358}. Best is trial 38 with value: 0.6980392156862745.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.6980392156862745, params {'learning_rate': 2.8337878528723636e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.05919640226444356, 'hidden_dropout_prob': 0.20334239998464515}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function for hyperparameter optimization of a BERTweet sequence classification model.\n",
    "    \n",
    "    Parameters:\n",
    "    - trial (optuna.trial.Trial): A trial object that suggests hyperparameter values for optimization.\n",
    "    \n",
    "    Returns:\n",
    "    - best_validation_accuracy (float): The best accuracy obtained on the validation set during training.\n",
    "    \"\"\"\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True)\n",
    "    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 1, 5)\n",
    "    per_device_train_batch_size = trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32])\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.0, 0.1)\n",
    "    hidden_dropout_prob = trial.suggest_float(\"hidden_dropout_prob\", 0.1, 0.5)\n",
    "    \n",
    "    # Configure the model with hyperparameters and predefined architecture\n",
    "    config = AutoConfig.from_pretrained(\"vinai/bertweet-base\", num_labels=3, hidden_dropout_prob=hidden_dropout_prob)\n",
    "    model = AutoModelForSequenceClassification.from_config(config)\n",
    "    model.to('cpu')\n",
    "    \n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"model_dir\",\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=32,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_steps=2000,\n",
    "        metric_for_best_model='accuracy',\n",
    "        logging_dir='./logs',\n",
    "        greater_is_better=True,\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "    \n",
    "    # Initialize the trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    best_validation_accuracy = trainer.evaluate()[\"eval_accuracy\"]\n",
    "\n",
    "    return best_validation_accuracy\n",
    "\n",
    "#Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print the best trial's score and hyperparameters\n",
    "print(f'Best trial: score {study.best_trial.value}, params {study.best_trial.params}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1e1a236-ab6d-45a6-90c4-ec2cb06c30b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/miniconda3/envs/env1/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7140' max='7140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7140/7140 46:26, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.114800</td>\n",
       "      <td>1.087570</td>\n",
       "      <td>0.411520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.852350</td>\n",
       "      <td>0.602206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.825800</td>\n",
       "      <td>0.807290</td>\n",
       "      <td>0.653922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.751000</td>\n",
       "      <td>0.766816</td>\n",
       "      <td>0.670588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.702400</td>\n",
       "      <td>0.920519</td>\n",
       "      <td>0.680392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.637200</td>\n",
       "      <td>0.773282</td>\n",
       "      <td>0.697059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.638800</td>\n",
       "      <td>0.736009</td>\n",
       "      <td>0.704167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.560900</td>\n",
       "      <td>0.778918</td>\n",
       "      <td>0.703186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.560400</td>\n",
       "      <td>0.771262</td>\n",
       "      <td>0.705147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.525600</td>\n",
       "      <td>0.770829</td>\n",
       "      <td>0.703676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.500200</td>\n",
       "      <td>0.788945</td>\n",
       "      <td>0.698775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.495900</td>\n",
       "      <td>0.809511</td>\n",
       "      <td>0.702941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.470400</td>\n",
       "      <td>0.827394</td>\n",
       "      <td>0.706863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.444800</td>\n",
       "      <td>0.827907</td>\n",
       "      <td>0.708088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7140, training_loss=0.6553010625331676, metrics={'train_runtime': 2787.6425, 'train_samples_per_second': 40.981, 'train_steps_per_second': 2.561, 'total_flos': 2230872890561280.0, 'train_loss': 0.6553010625331676, 'epoch': 6.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting hyperparameters from best trial\n",
    "best_params = {\n",
    "    'learning_rate': 2.8337878528723636e-05,\n",
    "    'num_train_epochs': 6,#Original found was 4. Changing it to get better results. \n",
    "    'per_device_train_batch_size': 16,\n",
    "    'weight_decay': 0.05919640226444356,\n",
    "    'hidden_dropout_prob': 0.20334239998464515\n",
    "}\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"vinai/bertweet-base\", num_labels=3, hidden_dropout_prob=best_params['hidden_dropout_prob'])\n",
    "model = AutoModelForSequenceClassification.from_config(config)\n",
    "model.to('cpu')\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"model_dir\",\n",
    "    per_device_train_batch_size=best_params['per_device_train_batch_size'],\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=best_params['num_train_epochs'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    weight_decay=best_params['weight_decay'],\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=2000,\n",
    "    metric_for_best_model='accuracy',\n",
    "    logging_dir='./logs',\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf179b13-5ffe-4ce9-ba8f-99d5ce93cfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7376    0.7889    0.7624      1265\n",
      "           1     0.7970    0.5854    0.6750      1194\n",
      "           2     0.6395    0.7298    0.6816      1621\n",
      "\n",
      "    accuracy                         0.7059      4080\n",
      "   macro avg     0.7247    0.7014    0.7064      4080\n",
      "weighted avg     0.7160    0.7059    0.7048      4080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on validation data\n",
    "predictions, labels, _ = trainer.predict(test_dataset)\n",
    "predictions = predictions.argmax(-1)\n",
    "\n",
    "print(classification_report(labels, predictions, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8b6f5f4-9f00-45ee-b0c4-52907722ccf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(labels, predictions)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "679c6c2e-dbb7-4146-8a56-11dd86353cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for class positive (Class value: 0):\n",
      "Specificity: 0.8413\n",
      "FPR: 0.1587\n",
      "Precision: 0.7376\n",
      "\n",
      "Metrics for class negative (Class value: 1):\n",
      "Specificity: 0.9245\n",
      "FPR: 0.0755\n",
      "Precision: 0.797\n",
      "\n",
      "Metrics for class neutral (Class value: 2):\n",
      "Specificity: 0.7179\n",
      "FPR: 0.2821\n",
      "Precision: 0.6395\n",
      "\n",
      "Overall accuracy: 0.7059\n",
      "Weighted average specificity: 0.8166\n",
      "Weighted average FPR: 0.1834\n",
      "Macro average specificity: 0.8279\n",
      "Macro average FPR: 0.1721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = np.array([[998, 26, 241], \n",
    "               [69, 699, 426], \n",
    "               [286, 152, 1183]])\n",
    "\n",
    "compute_FPR_spec_metrics(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8c96f15-30e4-4ccb-91cc-18d2bc1a1415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: how i wish the result is true\n",
      "Predicted: 0, Actual: 2\n",
      "---------------------\n",
      "Tweet: back at the vet and it is not good\n",
      "Predicted: 0, Actual: 1\n",
      "---------------------\n",
      "Tweet:  dinner done shower done now time to chill with block of chocolate\n",
      "Predicted: 2, Actual: 0\n",
      "---------------------\n",
      "Tweet:  it is a dreary monday morning and i slept like give me a break\n",
      "Predicted: 2, Actual: 1\n",
      "---------------------\n",
      "Tweet:  two macaroons go into a barone says oh your a nut  wow i need to get out more\n",
      "Predicted: 2, Actual: 0\n",
      "---------------------\n",
      "Tweet: _radio yeah s i feel all funny cause i have not slept enough  i woke my mum up cause i was singing she is not impressed s you\n",
      "Predicted: 2, Actual: 1\n",
      "---------------------\n",
      "Tweet:  that would be soooooo much and geeky to the ultimate level but i work  to am\n",
      "Predicted: 2, Actual: 0\n",
      "---------------------\n",
      "Tweet: on my way to school of my last friday of high school ever  and i do not even get to see holly gabbie and hannah\n",
      "Predicted: 2, Actual: 1\n",
      "---------------------\n",
      "Tweet: oh and i am obviously back on my stupid sleep schedule luckily church is not until  tomorrow\n",
      "Predicted: 1, Actual: 2\n",
      "---------------------\n",
      "Tweet: jesusi am being slammed via dms from the papaya lobbyists  ok holy  mangosteen durian or papayaor cybersecurity on a stick\n",
      "Predicted: 2, Actual: 1\n",
      "---------------------\n",
      "Tweet:  umhow long has it been since you slept startin to worry over here well i hope you are having fun lots of love to you\n",
      "Predicted: 0, Actual: 2\n",
      "---------------------\n",
      "Tweet: apparently today is happy star wars day  i am suppose to say may the th be with you\n",
      "Predicted: 0, Actual: 2\n",
      "---------------------\n",
      "Tweet:  um that is really scary please be safe  btw ill be in orlando next week\n",
      "Predicted: 0, Actual: 1\n",
      "---------------------\n",
      "Tweet: ian is waiting for a very important pic\n",
      "Predicted: 0, Actual: 2\n",
      "---------------------\n",
      "Tweet: getting anxious for blink s new album\n",
      "Predicted: 2, Actual: 1\n",
      "---------------------\n",
      "Tweet: _l thanksi think your the first girl to say thatbesides my mom\n",
      "Predicted: 2, Actual: 0\n",
      "---------------------\n",
      "Tweet:  i told that joke onstage at butlins in  one person laughed scarred for life at \n",
      "Predicted: 2, Actual: 1\n",
      "---------------------\n",
      "Tweet: goin to bed wsmokey\n",
      "Predicted: 0, Actual: 2\n",
      "---------------------\n",
      "Tweet:  i walk to  from workabout  minsthink that makes it worse   improves once indoors tho\n",
      "Predicted: 1, Actual: 2\n",
      "---------------------\n",
      "Tweet:   apple store is down for updates what is coming i wonder\n",
      "Predicted: 2, Actual: 1\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "def display_misclassified_tweets(predictions, labels, test_texts, num_display=20):\n",
    "    misclassified_idxs = (predictions != labels).nonzero()[0]\n",
    "    misclassified_texts = test_texts.iloc[misclassified_idxs].tolist()\n",
    "    misclassified_preds = predictions[misclassified_idxs]\n",
    "    misclassified_labels = labels[misclassified_idxs]\n",
    "\n",
    "    for idx in range(min(num_display, len(misclassified_texts))):\n",
    "        print(f\"Tweet: {misclassified_texts[idx]}\")\n",
    "        print(f\"Predicted: {misclassified_preds[idx]}, Actual: {misclassified_labels[idx]}\")\n",
    "        print(\"---------------------\")\n",
    "\n",
    "display_misclassified_tweets(predictions, labels, test_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a2a60-79de-4120-b513-cfda0e3efb37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
