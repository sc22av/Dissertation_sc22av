{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b223d6c-9353-4452-a94f-868b6c299873",
   "metadata": {},
   "source": [
    "### FinBERT IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8efa810b-57db-49ff-8854-ad149c020245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09662bc1-68f8-47d6-b1c6-9c223f1974cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is built with MPS\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_built():\n",
    "    print(\"PyTorch is built with MPS\")\n",
    "else:\n",
    "    print(\"MPS not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32238be-4d67-4fb1-8dc7-e1928e16c19f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"MPS device not found\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9a17834-a599-4c46-91c0-a5c613b64769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#torch.set_default_device('mps')\n",
    "\n",
    "mod = torch.nn.Linear(20,30)\n",
    "print(mod.weight.device)\n",
    "print(mod(torch.randn(128, 20)).device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36919332-ba6c-4060-a23b-b2b95366f065",
   "metadata": {},
   "source": [
    "## PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "202d357a-d557-4ade-bda3-be0e976af7ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic utilities\n",
    "import os\n",
    "import platform\n",
    "\n",
    "# Data handling and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Text preprocessing and sentiment analysis utilities\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Model evaluation, data splitting, and scikit-learn utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, f1_score, recall_score, \n",
    "                             precision_score, confusion_matrix, classification_report)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Word embeddings and NLP models\n",
    "import gensim\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# TensorFlow utilities\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "#import tensorflow_text as text  # Uncomment if needed\n",
    "\n",
    "# PyTorch utilities\n",
    "import torch\n",
    "\n",
    "# Optimization utilities\n",
    "import optuna\n",
    "\n",
    "# Miscellaneous\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "179d0833-9d0b-4bae-9ef0-d5fe99533bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine: x86_64\n",
      "Platform: macOS-10.16-x86_64-i386-64bit\n",
      "Mac Version: ('10.16', ('', '', ''), 'x86_64')\n",
      "Processor: i386\n",
      "Python Version: 3.9.12\n"
     ]
    }
   ],
   "source": [
    "def general_info():\n",
    "    print(\"Machine:\", platform.machine())\n",
    "    print(\"Platform:\", platform.platform())\n",
    "    print(\"Mac Version:\", platform.mac_ver())\n",
    "    print(\"Processor:\", platform.processor())\n",
    "    print(\"Python Version:\", platform.python_version())\n",
    "  \n",
    "general_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82537b29-dd5f-40d3-92d5-feb554b1725d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Jupyter core packages...\n",
      "IPython          : 8.2.0\n",
      "ipykernel        : 6.9.1\n",
      "ipywidgets       : 7.6.5\n",
      "jupyter_client   : 6.1.12\n",
      "jupyter_core     : 4.9.2\n",
      "jupyter_server   : 1.13.5\n",
      "jupyterlab       : 3.3.2\n",
      "nbclient         : 0.5.13\n",
      "nbconvert        : 6.4.4\n",
      "nbformat         : 5.3.0\n",
      "notebook         : 6.4.8\n",
      "qtconsole        : 5.3.0\n",
      "traitlets        : 5.1.1\n"
     ]
    }
   ],
   "source": [
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7587262-97e8-4ad7-9c88-9cdb644d490d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S No.</th>\n",
       "      <th>Title</th>\n",
       "      <th>Decisions</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SpiceJet to issue 6.4 crore warrants to promoters</td>\n",
       "      <td>{\"SpiceJet\": \"neutral\"}</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MMTC Q2 net loss at Rs 10.4 crore</td>\n",
       "      <td>{\"MMTC\": \"neutral\"}</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mid-cap funds can deliver more, stay put: Experts</td>\n",
       "      <td>{\"Mid-cap funds\": \"positive\"}</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mid caps now turn into market darlings</td>\n",
       "      <td>{\"Mid caps\": \"positive\"}</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Market seeing patience, if not conviction: Pra...</td>\n",
       "      <td>{\"Market\": \"neutral\"}</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10748</th>\n",
       "      <td>10749</td>\n",
       "      <td>Negative on Chambal, Advanta: Mitesh Thacker</td>\n",
       "      <td>{\"Chambal\": \"negative\", \"Advanta\": \"negative\"}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10749</th>\n",
       "      <td>10750</td>\n",
       "      <td>Small, Mid-cap stocks may emerge outperformers</td>\n",
       "      <td>{\"Small\": \"positive\", \"Mid-cap stocks\": \"posit...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10750</th>\n",
       "      <td>10751</td>\n",
       "      <td>Rupee slips against US dollar</td>\n",
       "      <td>{\"Rupee\": \"negative\", \"US dollar\": \"neutral\"}</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10751</th>\n",
       "      <td>10752</td>\n",
       "      <td>Rupee weak against US dollar</td>\n",
       "      <td>{\"Rupee\": \"negative\", \"US dollar\": \"neutral\"}</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10752</th>\n",
       "      <td>10753</td>\n",
       "      <td>Australia shares flat; energy drags</td>\n",
       "      <td>{\"Australia shares\": \"neutral\", \"energy\": \"neu...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10753 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       S No.                                              Title  \\\n",
       "0          1  SpiceJet to issue 6.4 crore warrants to promoters   \n",
       "1          2                  MMTC Q2 net loss at Rs 10.4 crore   \n",
       "2          3  Mid-cap funds can deliver more, stay put: Experts   \n",
       "3          4             Mid caps now turn into market darlings   \n",
       "4          5  Market seeing patience, if not conviction: Pra...   \n",
       "...      ...                                                ...   \n",
       "10748  10749       Negative on Chambal, Advanta: Mitesh Thacker   \n",
       "10749  10750     Small, Mid-cap stocks may emerge outperformers   \n",
       "10750  10751                      Rupee slips against US dollar   \n",
       "10751  10752                       Rupee weak against US dollar   \n",
       "10752  10753                Australia shares flat; energy drags   \n",
       "\n",
       "                                               Decisions  Words  \n",
       "0                                {\"SpiceJet\": \"neutral\"}      8  \n",
       "1                                    {\"MMTC\": \"neutral\"}      8  \n",
       "2                          {\"Mid-cap funds\": \"positive\"}      8  \n",
       "3                               {\"Mid caps\": \"positive\"}      7  \n",
       "4                                  {\"Market\": \"neutral\"}      8  \n",
       "...                                                  ...    ...  \n",
       "10748     {\"Chambal\": \"negative\", \"Advanta\": \"negative\"}      6  \n",
       "10749  {\"Small\": \"positive\", \"Mid-cap stocks\": \"posit...      6  \n",
       "10750      {\"Rupee\": \"negative\", \"US dollar\": \"neutral\"}      5  \n",
       "10751      {\"Rupee\": \"negative\", \"US dollar\": \"neutral\"}      5  \n",
       "10752  {\"Australia shares\": \"neutral\", \"energy\": \"neu...      5  \n",
       "\n",
       "[10753 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the path to the dataset, loading the csv into Pandas DataFrame\n",
    "data_pth = '/users/anshulvij/Desktop/Masters Project/Datasets/SEntFiN-v1.1.csv'\n",
    "df = pd.read_csv(data_pth)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04741ed1-4b2d-47c9-8487-59cdb35346e4",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING STEPS IMPLEMENTED BELOW:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b44d39d0-b940-4c17-80d2-1c5bdf7dace3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_rows_by_colon_count(data, column):\n",
    "    \"\"\"\n",
    "    Filters out rows where the count of colons in the specified column exceeds one.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The DataFrame to be processed.\n",
    "    - column (str): The column name in which colon count needs to be checked.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame after filtering out specific rows.\n",
    "    \"\"\"\n",
    "    condition = data[column].apply(lambda entry: str(entry).count(':') > 1)\n",
    "    return data[~condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "489c7bf2-5815-4492-90b0-647dbc6563eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Filtering Stage-1 Step-1: Total Rows - 7903\n"
     ]
    }
   ],
   "source": [
    "df = filter_rows_by_colon_count(df, 'Decisions')\n",
    "print(f\"Post Filtering Stage-1 Step-1: Total Rows - {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64e4ec52-d9b9-4a92-88ca-41431c308443",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Filtering Stage-1 Step-2: Total Rows - 7903\n"
     ]
    }
   ],
   "source": [
    "def transform_decision_data(data, column):\n",
    "    \"\"\"\n",
    "    Transforms the specified column of the DataFrame by extracting 'Entity' and 'Polarity' \n",
    "    from a dictionary representation. Ensures that strings mimicking dictionaries are \n",
    "    converted to actual dictionaries.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The DataFrame to be processed.\n",
    "    - column (str): The column name which contains dictionary or its string representation.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Transformed DataFrame with 'Headlines', 'Entity', and 'Sentiment' columns.\n",
    "    \"\"\"\n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    # Convert string representation of dictionary to actual dictionary\n",
    "    data_copy[column] = data_copy[column].apply(lambda item: ast.literal_eval(item) if isinstance(item, str) else item)\n",
    "    \n",
    "    # Extract key and value from the dictionary\n",
    "    data_copy['Entity'] = data_copy[column].apply(lambda item: list(item.keys())[0] if isinstance(item, dict) else None)\n",
    "    data_copy['Sentiment'] = data_copy[column].apply(lambda item: list(item.values())[0] if isinstance(item, dict) else None)\n",
    "    \n",
    "    return data_copy[['Title', 'Entity', 'Sentiment']].rename(columns={'Title': 'Headlines'})\n",
    "\n",
    "processed_df = transform_decision_data(df, 'Decisions')\n",
    "\n",
    "#Dropping the entity column as the rest have been set aside in the transform_decision_data\n",
    "processed_df = processed_df.drop(columns=['Entity'])\n",
    "\n",
    "\n",
    "print(f\"Post Filtering Stage-1 Step-2: Total Rows - {len(processed_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6602101e-94e0-46f2-91c8-3485859899bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " Headlines    0\n",
      "Sentiment    0\n",
      "dtype: int64\n",
      "Post Filtering Stage-2 Step-1: Total Rows - 7903\n"
     ]
    }
   ],
   "source": [
    "def check_missing_data(dataframe):\n",
    "    \"\"\"\n",
    "    Checks and returns the number of missing values in each column of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe (pd.DataFrame): The DataFrame to be checked.\n",
    "\n",
    "    Returns:\n",
    "    - Series: Number of missing values for each column.\n",
    "    \"\"\"\n",
    "    return dataframe.isnull().sum()\n",
    "\n",
    "print(\"Missing Values:\\n\", check_missing_data(processed_df))\n",
    "processed_df = processed_df.dropna()\n",
    "print(f\"Post Filtering Stage-2 Step-1: Total Rows - {len(processed_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4c724b2-6612-494c-815e-8b707b027b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Filtering Stage-2 Step-2: Total Rows - 7903\n"
     ]
    }
   ],
   "source": [
    "def refine_headlines(column):\n",
    "    \"\"\"\n",
    "    Cleans and refines a given text column. The function lowercases the text, removes \n",
    "    HTML content, URLs, non-alphanumeric characters, and stopwords. It also lemmatises \n",
    "    each word for better text consistency.\n",
    "\n",
    "    Parameters:\n",
    "    - column (pd.Series): The column containing text data to be refined.\n",
    "\n",
    "    Returns:\n",
    "    - pd.Series: The refined column.\n",
    "    \"\"\"\n",
    "    column = column.str.lower()\n",
    "    \n",
    "    # Check if text looks like filename or not\n",
    "    def extract_text(text):\n",
    "        if re.match(r'^[A-Za-z0-9_\\-\\.]+$', text):\n",
    "            return text\n",
    "        return BeautifulSoup(text, 'lxml').get_text()\n",
    "    \n",
    "    column = column.str.replace('http\\S+|www.\\S+|[^\\w\\s]', '', regex=True)\n",
    "    \n",
    "    return column\n",
    "\n",
    "processed_df['Headlines'] = refine_headlines(processed_df['Headlines'])\n",
    "print(f\"Post Filtering Stage-2 Step-2: Total Rows - {len(processed_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b710d3b6-9909-4848-a925-1f940efcb215",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Filtering Stage-2 Step-3 Total Rows - 7858\n"
     ]
    }
   ],
   "source": [
    "# Detect and remove duplicate rows from the DataFrame\n",
    "duplicated_rows = processed_df[processed_df.duplicated()]\n",
    "processed_df.drop_duplicates(inplace=True)\n",
    "print(f\"Post Filtering Stage-2 Step-3 Total Rows - {len(processed_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad7b3768-c476-4f79-8b92-cb67a127e361",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of each sentiment:\n",
      "positive    2830\n",
      "neutral     2657\n",
      "negative    2371\n",
      "Name: Sentiment, dtype: int64\n",
      "positive    36.014253\n",
      "neutral     33.812675\n",
      "negative    30.173072\n",
      "Name: Sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def display_sentiment_counts(dataframe, column_name='Sentiment'):\n",
    "    \"\"\"\n",
    "    Displays the frequency and relative percentage of each sentiment value in the given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe (pd.DataFrame): The DataFrame containing sentiment data.\n",
    "    - column_name (str, optional): The name of the column containing sentiment values. Default is 'Sentiment'.\n",
    "\n",
    "    Prints:\n",
    "    - Sentiment counts and their relative percentages.\n",
    "    \"\"\"\n",
    "    sentiment_counts = dataframe[column_name].value_counts()\n",
    "    print(\"\\nCount of each sentiment:\")\n",
    "    print(sentiment_counts)\n",
    "\n",
    "    sentiment_percentages = dataframe[column_name].value_counts(normalize=True)*100\n",
    "    print(sentiment_percentages)\n",
    "\n",
    "display_sentiment_counts(processed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61767d75-f1a9-4b4a-ac4e-df6fe59f13e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate and visualize the distribution of sentiment values in the DataFrame using a bar chart.\n",
    "# Each bar is labelled with the sentiment count and its relative percentage.\n",
    "\n",
    "# Calculate sentiment frequency and its relative percentage\n",
    "sentiment_frequency = processed_df['Sentiment'].value_counts()\n",
    "sentiment_ratio = processed_df['Sentiment'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Display sentiment distribution using a bar chart\n",
    "bars = plt.bar(sentiment_frequency.index, sentiment_frequency.values, alpha=0.8)\n",
    "\n",
    "# Adjust the y-axis limit\n",
    "plt.ylim(0, max(sentiment_frequency.values) * 1.15)  # Increase the upper limit by 15% of the highest bar value\n",
    "\n",
    "# Label each bar with the sentiment count and its percentage\n",
    "for idx, bar in enumerate(bars):\n",
    "    yval = bar.get_height()\n",
    "    sentiment_label = sentiment_frequency.index[idx]\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + max(sentiment_frequency.values) * 0.05, \n",
    "             f'{int(yval)} ({sentiment_ratio[sentiment_label]:.2f}%)',\n",
    "             ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Sentiment Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Sentiment Distribution Visualization')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8670de32-ba30-4a4c-9991-03c4868a4948",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spicejet to issue 64 crore warrants to promoters</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mmtc q2 net loss at rs 104 crore</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>midcap funds can deliver more stay put experts</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mid caps now turn into market darlings</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>market seeing patience if not conviction praka...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10697</th>\n",
       "      <td>vedantacairn deal may not go through ajay bagga</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10700</th>\n",
       "      <td>wall street opens flat sp 500 near record</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10710</th>\n",
       "      <td>heard on the street dutchman mf fiis</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10714</th>\n",
       "      <td>rebound for russia and china lifts stocks</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10732</th>\n",
       "      <td>masoor gram prices weaken on sluggish demand</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7858 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Headlines Sentiment\n",
       "0       spicejet to issue 64 crore warrants to promoters   neutral\n",
       "1                       mmtc q2 net loss at rs 104 crore   neutral\n",
       "2         midcap funds can deliver more stay put experts  positive\n",
       "3                 mid caps now turn into market darlings  positive\n",
       "4      market seeing patience if not conviction praka...   neutral\n",
       "...                                                  ...       ...\n",
       "10697    vedantacairn deal may not go through ajay bagga  negative\n",
       "10700          wall street opens flat sp 500 near record   neutral\n",
       "10710               heard on the street dutchman mf fiis   neutral\n",
       "10714          rebound for russia and china lifts stocks  positive\n",
       "10732       masoor gram prices weaken on sluggish demand  negative\n",
       "\n",
       "[7858 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bedecc5-9210-4f8e-a3f8-077b7377258b",
   "metadata": {},
   "source": [
    "### FINBERT IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e0d1c53-2dae-41e0-8ef0-cb5f14055779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_and_tokenizer():\n",
    "    \"\"\"\n",
    "    Initialize the model and tokenizer for the specified pretrained version.\n",
    "\n",
    "    Returns:\n",
    "    - tokenizer: Initialized tokenizer\n",
    "    - model: Initialized model\n",
    "    \"\"\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('ProsusAI/finbert')\n",
    "    tokenizer = AutoTokenizer.from_pretrained('ProsusAI/finbert', padding=True, truncation=True)\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a6617bc-dbc9-4fdc-94d2-2c90ed24c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df):\n",
    "    \"\"\"\n",
    "    Maps sentiment to a target value.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing the 'Sentiment' column.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Processed DataFrame with an additional 'Target' column.\n",
    "    \"\"\"\n",
    "    target_map = {'neutral': 2, 'positive': 0, 'negative': 1}\n",
    "    df['Target'] = df['Sentiment'].map(target_map)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2c4a602-c4ee-4f6b-93ed-e6420ed4a083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_FPR_spec_metrics(cm, labels=[\"positive\", \"negative\", \"neutral\"]):\n",
    "    \"\"\"\n",
    "    Compute specificity, FPR, precision for each class, and the overall accuracy given a 3x3 confusion matrix.\n",
    "    Also, computes weighted and macro average for FPR and specificity.\n",
    "\n",
    "    Args:\n",
    "    - cm (numpy array): 3x3 confusion matrix\n",
    "    - labels (list): List of class labels in order\n",
    "\n",
    "    Returns:\n",
    "    None. It will print the results directly.\n",
    "    \"\"\"\n",
    "    \n",
    "    specificities = []\n",
    "    fprs = []\n",
    "    precisions = []\n",
    "\n",
    "    for i in range(3):\n",
    "        tp = cm[i, i]\n",
    "        tn = sum(cm[j, j] for j in range(3) if j != i)\n",
    "        fp = sum(cm[j, i] for j in range(3) if j != i)\n",
    "        fn = sum(cm[i, j] for j in range(3) if j != i)\n",
    "        \n",
    "        specificity = tn / (tn + fp) if tn + fp != 0 else 0\n",
    "        fpr = 1 - specificity\n",
    "        precision = tp / (tp + fp) if tp + fp != 0 else 0\n",
    "        \n",
    "        specificities.append(round(specificity, 4))\n",
    "        fprs.append(round(fpr, 4))\n",
    "        precisions.append(round(precision, 4))\n",
    "    \n",
    "    # Print the class values with their corresponding metrics\n",
    "    for i, label in enumerate(labels):\n",
    "        print(f\"Metrics for class {label} (Class value: {i}):\")\n",
    "        print(f\"Specificity: {specificities[i]}\")\n",
    "        print(f\"FPR: {fprs[i]}\")\n",
    "        print(f\"Precision: {precisions[i]}\\n\")\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    accuracy = round(np.trace(cm) / np.sum(cm), 4)\n",
    "    print(f\"Overall accuracy: {accuracy}\")\n",
    "\n",
    "    # Calculate true values for each class for weighting purposes\n",
    "    true_values = np.sum(cm, axis=1)\n",
    "    total_true_values = np.sum(true_values)\n",
    "\n",
    "    # Calculate weighted average specificity and FPR\n",
    "    weighted_avg_spec = round(sum(specificities[i] * true_values[i] for i in range(3)) / total_true_values, 4)\n",
    "    weighted_avg_fpr = round(sum(fprs[i] * true_values[i] for i in range(3)) / total_true_values, 4)\n",
    "\n",
    "    # Calculate macro average specificity and FPR\n",
    "    macro_avg_spec = round(np.mean(specificities), 4)\n",
    "    macro_avg_fpr = round(np.mean(fprs), 4)\n",
    "\n",
    "    print(f\"Weighted average specificity: {weighted_avg_spec}\")\n",
    "    print(f\"Weighted average FPR: {weighted_avg_fpr}\")\n",
    "    print(f\"Macro average specificity: {macro_avg_spec}\")\n",
    "    print(f\"Macro average FPR: {macro_avg_fpr}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bdc5dc7-e48e-4d46-b5db-e13a553a238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(X, y, tokenizer):\n",
    "    \"\"\"\n",
    "    Prepares the tokenized dataset for training, validation, and testing.\n",
    "\n",
    "    Parameters:\n",
    "    - X (np.array): Array of sentences.\n",
    "    - y (np.array): Array of target values.\n",
    "    - tokenizer: Tokenizer instance.\n",
    "\n",
    "    Returns:\n",
    "    - train_dataset, val_dataset, test_dataset: Torch Dataset objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=5)\n",
    "\n",
    "\n",
    "    # Encode data\n",
    "    train_encodings = tokenizer(list(X_train), truncation=True, padding=True)\n",
    "    val_encodings = tokenizer(list(X_val), truncation=True, padding=True)\n",
    "    test_encodings = tokenizer(list(X_test), truncation=True, padding=True)\n",
    "\n",
    "    # Convert encodings into Torch Dataset objects\n",
    "    train_dataset = SentimentDataset(train_encodings, y_train)\n",
    "    val_dataset = SentimentDataset(val_encodings, y_val)\n",
    "    test_dataset = SentimentDataset(test_encodings, y_test)\n",
    "    return train_dataset, val_dataset, test_dataset, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f15b1f9d-5b2d-44af-a8bf-adfeb75fd108",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class for sentiment analysis using tokenized encodings.\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8227b26-dfc6-4446-84eb-1bd0083fc9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Compute accuracy for predictions.\n",
    "\n",
    "    Parameters:\n",
    "    - pred: Prediction object with `label_ids` and `predictions` attributes.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary containing accuracy.\n",
    "    \"\"\"\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "775e72b6-0091-498d-bc2c-8039a3ed55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, train_dataset, val_dataset, model_init):\n",
    "    \"\"\"\n",
    "    Objective function for optimization. Trains and evaluates a model based on trial parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - trial (optuna.trial.Trial): A single trial of hyperparameter optimization.\n",
    "    - train_dataset: Training dataset.\n",
    "    - val_dataset: Validation dataset.\n",
    "    - model_init: Initialization function for the model.\n",
    "\n",
    "    Returns:\n",
    "    - float: Evaluation accuracy of the trained model.\n",
    "    \"\"\"\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"test_trainer\",\n",
    "        use_mps_device=True,\n",
    "        num_train_epochs=trial.suggest_int(\"num_train_epochs\", 1, 10),\n",
    "        per_device_train_batch_size=trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32, 64]),\n",
    "        per_device_eval_batch_size=64,\n",
    "        warmup_steps=trial.suggest_int(\"warmup_steps\", 0, 500),\n",
    "        weight_decay=trial.suggest_float(\"weight_decay\", 0.0, 0.1),\n",
    "        learning_rate=trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True),\n",
    "        logging_dir='./logs',\n",
    "        load_best_model_at_end=True,\n",
    "        logging_steps=250,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_steps=500,\n",
    "        metric_for_best_model='accuracy',\n",
    "        greater_is_better=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model_init=model_init,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    print(f\"Trainer is running on: {trainer.model.device}\")\n",
    "    trainer.train()\n",
    "    return trainer.evaluate()[\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "282c6a00-9027-408f-bca5-ba1370fe37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters(train_dataset, val_dataset, model_init, n_trials=50):\n",
    "    \"\"\"\n",
    "    Conduct hyperparameter optimization using Optuna.\n",
    "\n",
    "    Parameters:\n",
    "    - train_dataset: Training dataset.\n",
    "    - val_dataset: Validation dataset.\n",
    "    - model_init: Initialization function for the model.\n",
    "    - n_trials (int, optional): Number of trials. Defaults to 50.\n",
    "\n",
    "    Returns:\n",
    "    - optuna.study.Study: Optuna study object with optimization results.\n",
    "    \"\"\"\n",
    "    pruner = optuna.pruners.MedianPruner()\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "    study.optimize(lambda trial: objective(trial, train_dataset, val_dataset, model_init), n_trials=n_trials)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cdc3591-8f0a-4a03-93f9-b10278b03bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_best_params(train_dataset, val_dataset, model, best_params):\n",
    "    \"\"\"\n",
    "    Train the model with the best hyperparameters obtained from optimization.\n",
    "\n",
    "    Parameters:\n",
    "    - train_dataset: Training dataset.\n",
    "    - val_dataset: Validation dataset.\n",
    "    - model: Pretrained model.\n",
    "    - best_params (dict): Dictionary containing the best hyperparameters.\n",
    "\n",
    "    Returns:\n",
    "    - Trainer: Trainer object after training.\n",
    "    \"\"\"\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"model_dir\",\n",
    "        use_mps_device=True,\n",
    "        num_train_epochs=best_params[\"num_train_epochs\"],\n",
    "        per_device_train_batch_size=best_params[\"per_device_train_batch_size\"],\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        weight_decay=best_params[\"weight_decay\"],\n",
    "        warmup_steps=best_params[\"warmup_steps\"],\n",
    "        evaluation_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        save_steps=500,\n",
    "        logging_steps=250,\n",
    "        metric_for_best_model='accuracy',\n",
    "        greater_is_better=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    print(f\"Trainer is running on: {trainer.model.device}\")\n",
    "    trainer.train()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45afa379-819f-4269-9ce3-5f3bf1125000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_study_results(study):\n",
    "    \"\"\"\n",
    "    Print the optimization results of a study.\n",
    "\n",
    "    Parameters:\n",
    "    - study: The study object containing trials with their results and associated parameters.\n",
    "\n",
    "    Output:\n",
    "    Prints the trial number, its value (accuracy), and its parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nOptimization Results:\")\n",
    "    for i, trial in enumerate(study.trials):\n",
    "        print(f\"Trial {i + 1}:\")\n",
    "        print(f\"  Value (Accuracy): {trial.value}\")\n",
    "        print(f\"  Params: {trial.params}\")\n",
    "        print(\"---------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aeaf6d77-f4f4-402d-bd4f-3dc2232fb8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(trainer):\n",
    "    \"\"\"\n",
    "    Plots the training and validation loss from a trainer's log history.\n",
    "    \n",
    "    Parameters:\n",
    "    - trainer: An object containing the training state and its log history. \n",
    "               It is assumed that this object has an attribute 'state' which \n",
    "               further has a 'log_history' attribute storing the losses.\n",
    "\n",
    "    Output:\n",
    "    Displays a plot with training and validation losses over logging steps.\n",
    "    \"\"\"\n",
    "    # Extract training and validation loss from log history\n",
    "    training_losses = [x['loss'] for x in trainer.state.log_history if 'loss' in x]\n",
    "    validation_losses = [x['eval_loss'] for x in trainer.state.log_history if 'eval_loss' in x]\n",
    "\n",
    "    # Plot the losses\n",
    "    plt.plot(training_losses, label=\"Training Loss\")\n",
    "    plt.plot(validation_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Logging Steps\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76e60dbf-5873-465f-8104-e5d3496e70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(trainer, test_dataset,y_true, label_encoder):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a test dataset, prints the evaluation metrics, \n",
    "    and visualizes the confusion matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - trainer: An object responsible for training, evaluating, and predicting.\n",
    "               This object should have methods `evaluate` and `predict`.\n",
    "    - test_dataset: Dataset object on which the model is to be evaluated and predictions are to be made.\n",
    "    - y_true: The true labels for the test dataset.\n",
    "    - label_encoder: An encoder object that is used to transform labels. \n",
    "                     Should have a `classes_` attribute listing all unique class names.\n",
    "                     \n",
    "    Outputs:\n",
    "    - Prints the evaluation loss and accuracy on the test dataset.\n",
    "    - Prints a classification report with precision, recall, f1-score, and support.\n",
    "    - Displays a heatmap representation of the confusion matrix.\n",
    "    \"\"\"\n",
    "    # Evaluate on test dataset\n",
    "    test_results = trainer.evaluate(test_dataset)\n",
    "    print(\"\\nTest Set Evaluation:\")\n",
    "    print(f\"Evaluation Loss: {test_results['eval_loss']}\")\n",
    "    print(f\"Evaluation Accuracy: {test_results['eval_accuracy']}\")\n",
    "\n",
    "    # Get predictions\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "    # Convert target_names to string\n",
    "    target_names = [str(label) for label in label_encoder.classes_]\n",
    "\n",
    "    # Print classification report\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names, digits =4))\n",
    "\n",
    "    # Plot confusion matrix using seaborn\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Format annotations to integers\n",
    "    annot = np.array(cm).astype(str)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            annot[i, j] = str(int(cm[i, j]))\n",
    "\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.heatmap(cm, annot=annot, fmt=\"\", cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97c8d6bd-815c-41e6-bd7e-061623c02e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_incorrect_samples(trainer, test_dataset, label_encoder, tokenizer):\n",
    "    \"\"\"\n",
    "    Extracts incorrect samples from the test dataset based on the model's predictions.\n",
    "\n",
    "    This function aims to identify and decode misclassified samples from a given test dataset.\n",
    "    The output provides up to five sentences from the dataset that the model has incorrectly\n",
    "    predicted for each sentiment category (positive, negative, neutral).\n",
    "\n",
    "    Parameters:\n",
    "    - trainer: An object responsible for model operations. This object should have a `predict` method.\n",
    "    - test_dataset: Dataset object from which incorrect samples are to be extracted.\n",
    "    - label_encoder: An encoder object used to transform labels. Should have a `classes_` attribute listing unique class names.\n",
    "    - tokenizer: Tokenizer object to decode tokenized text samples back into string sentences.\n",
    "\n",
    "    Returns:\n",
    "    - sample_sentences: A dictionary with keys as sentiment labels (\"positive\", \"negative\", \"neutral\").\n",
    "                        Each key contains a nested dictionary with \"sentences\" (list of decoded sentences)\n",
    "                        and \"probabilities\" (model's predicted probabilities for the respective incorrect label).\n",
    "\n",
    "    Note:\n",
    "    The function is designed for sentiment analysis tasks with three sentiment categories (positive, negative, neutral).\n",
    "    It may require modifications for other tasks or categories.\n",
    "    \"\"\"\n",
    "    # Get model predictions\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "    # Extract true labels from the test_dataset\n",
    "    y_true = [sample['labels'].item() for sample in test_dataset]\n",
    "\n",
    "    # Convert test_dataset to dataframe\n",
    "    data = {\n",
    "        'text': [sample['input_ids'] for sample in test_dataset],\n",
    "        'label': y_true\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Filter incorrect predictions\n",
    "    incorrect_df = df[y_pred != df['label']].copy()\n",
    "    incorrect_df['predicted_label'] = y_pred[y_pred != df['label'].to_numpy()]\n",
    "\n",
    "    sample_sentences = {\n",
    "        \"positive\": {\"sentences\": [], \"probabilities\": []},\n",
    "        \"negative\": {\"sentences\": [], \"probabilities\": []},\n",
    "        \"neutral\": {\"sentences\": [], \"probabilities\": []}\n",
    "     }\n",
    "    \n",
    "    for label_text, label_num in [(\"positive\", 1), (\"negative\", 0), (\"neutral\", 2)]:\n",
    "    # Filter out incorrect samples for the specific label\n",
    "        label_incorrect_df = incorrect_df[incorrect_df['label'] == label_num]\n",
    "\n",
    "    # Sample up to 5 sentences\n",
    "        num_samples = min(5, len(label_incorrect_df))\n",
    "        sampled_texts = label_incorrect_df['text'].sample(n=num_samples, random_state=5)\n",
    "    # Debug: Print out the sampled_texts\n",
    "    #   print(f\"Sampled token sequences for {label_text}:\")\n",
    "    #   print(sampled_texts)\n",
    "        \n",
    "    # Decode the tokens back to sentences and get predicted probabilities\n",
    "        decoded_sentences = [tokenizer.decode(text.numpy(), skip_special_tokens=True) for text in sampled_texts]\n",
    "        predicted_labels = label_incorrect_df.loc[sampled_texts.index, 'predicted_label']\n",
    "        predicted_probs = [predictions.predictions[i][pred_label] for i, pred_label in enumerate(predicted_labels)]\n",
    "    # Debug: Print out the decoded sentences\n",
    "    #    print(f\"Decoded sentences for {label_text}:\")\n",
    "    #    print(decoded_sentences)\n",
    "\n",
    "    # Store the sentences and probabilities\n",
    "        sample_sentences[label_text]['sentences'] = decoded_sentences\n",
    "        sample_sentences[label_text]['probabilities'] = predicted_probs\n",
    "\n",
    "    return sample_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9899db1-b903-4154-82a8-15392a98c826",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:03:43,439] A new study created in memory with name: no-name-64d00872-62d2-413d-96fb-29926d38494f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='220' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [220/220 03:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:06:49,157] Trial 0 finished with value: 0.7288135593220338 and parameters: {'num_train_epochs': 10, 'per_device_train_batch_size': 64, 'warmup_steps': 416, 'weight_decay': 0.0864178182365929, 'learning_rate': 4.006946584754387e-05}. Best is trial 0 with value: 0.7288135593220338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='516' max='516' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [516/516 02:15, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.725900</td>\n",
       "      <td>0.628299</td>\n",
       "      <td>0.755932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.622800</td>\n",
       "      <td>0.582620</td>\n",
       "      <td>0.786441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:09:10,215] Trial 1 finished with value: 0.7864406779661017 and parameters: {'num_train_epochs': 6, 'per_device_train_batch_size': 16, 'warmup_steps': 178, 'weight_decay': 0.05953659664645361, 'learning_rate': 0.00011849058183535206}. Best is trial 1 with value: 0.7864406779661017.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [344/344 01:00, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.770100</td>\n",
       "      <td>0.729751</td>\n",
       "      <td>0.725424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:10:16,189] Trial 2 finished with value: 0.7220338983050848 and parameters: {'num_train_epochs': 2, 'per_device_train_batch_size': 8, 'warmup_steps': 119, 'weight_decay': 0.026570422078083133, 'learning_rate': 1.9273357280023197e-05}. Best is trial 1 with value: 0.7864406779661017.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1548' max='1548' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1548/1548 04:43, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.734000</td>\n",
       "      <td>0.663912</td>\n",
       "      <td>0.752542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.653700</td>\n",
       "      <td>0.623177</td>\n",
       "      <td>0.772881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.640300</td>\n",
       "      <td>0.596897</td>\n",
       "      <td>0.776271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.587800</td>\n",
       "      <td>0.584674</td>\n",
       "      <td>0.796610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.605400</td>\n",
       "      <td>0.574753</td>\n",
       "      <td>0.793220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.583100</td>\n",
       "      <td>0.570488</td>\n",
       "      <td>0.796610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:15:05,094] Trial 3 finished with value: 0.7966101694915254 and parameters: {'num_train_epochs': 9, 'per_device_train_batch_size': 8, 'warmup_steps': 35, 'weight_decay': 0.010844831774157916, 'learning_rate': 6.767340190117872e-05}. Best is trial 3 with value: 0.7966101694915254.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [344/344 01:00, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>0.573361</td>\n",
       "      <td>0.779661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:16:11,042] Trial 4 finished with value: 0.8101694915254237 and parameters: {'num_train_epochs': 2, 'per_device_train_batch_size': 8, 'warmup_steps': 451, 'weight_decay': 0.022720293054870666, 'learning_rate': 0.000693522105434715}. Best is trial 4 with value: 0.8101694915254237.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [344/344 01:00, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.748100</td>\n",
       "      <td>0.685002</td>\n",
       "      <td>0.738983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:17:16,863] Trial 5 finished with value: 0.7559322033898305 and parameters: {'num_train_epochs': 2, 'per_device_train_batch_size': 8, 'warmup_steps': 317, 'weight_decay': 0.02136262824388965, 'learning_rate': 0.0001013144918873407}. Best is trial 4 with value: 0.8101694915254237.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='154' max='154' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [154/154 02:05, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:19:27,571] Trial 6 finished with value: 0.8372881355932204 and parameters: {'num_train_epochs': 7, 'per_device_train_batch_size': 64, 'warmup_steps': 50, 'weight_decay': 0.06290031023039559, 'learning_rate': 0.0023661656003565383}. Best is trial 6 with value: 0.8372881355932204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='430' max='430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [430/430 03:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.777200</td>\n",
       "      <td>0.725944</td>\n",
       "      <td>0.732203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:22:51,830] Trial 7 finished with value: 0.735593220338983 and parameters: {'num_train_epochs': 10, 'per_device_train_batch_size': 32, 'warmup_steps': 323, 'weight_decay': 0.08995642429250524, 'learning_rate': 1.7017878712098978e-05}. Best is trial 6 with value: 0.8372881355932204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='688' max='688' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [688/688 02:04, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.637900</td>\n",
       "      <td>0.476743</td>\n",
       "      <td>0.823729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.678900</td>\n",
       "      <td>0.862941</td>\n",
       "      <td>0.708475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:25:01,930] Trial 8 finished with value: 0.7084745762711865 and parameters: {'num_train_epochs': 4, 'per_device_train_batch_size': 8, 'warmup_steps': 480, 'weight_decay': 0.008707000793174813, 'learning_rate': 0.006649994678744354}. Best is trial 6 with value: 0.8372881355932204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [344/344 02:36, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.698300</td>\n",
       "      <td>0.576298</td>\n",
       "      <td>0.783051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:27:43,866] Trial 9 finished with value: 0.8033898305084746 and parameters: {'num_train_epochs': 8, 'per_device_train_batch_size': 32, 'warmup_steps': 416, 'weight_decay': 0.09149230988250258, 'learning_rate': 0.0003429655698153725}. Best is trial 6 with value: 0.8372881355932204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:46, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:29:36,131] Trial 10 finished with value: 0.8440677966101695 and parameters: {'num_train_epochs': 6, 'per_device_train_batch_size': 64, 'warmup_steps': 15, 'weight_decay': 0.056417565762603525, 'learning_rate': 0.0025972802613795243}. Best is trial 10 with value: 0.8440677966101695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:47, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:31:27,753] Trial 11 finished with value: 0.8406779661016949 and parameters: {'num_train_epochs': 6, 'per_device_train_batch_size': 64, 'warmup_steps': 6, 'weight_decay': 0.057167535327949846, 'learning_rate': 0.0026892793271674504}. Best is trial 10 with value: 0.8440677966101695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 01:28, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:33:01,433] Trial 12 finished with value: 0.847457627118644 and parameters: {'num_train_epochs': 5, 'per_device_train_batch_size': 64, 'warmup_steps': 2, 'weight_decay': 0.044354486614017856, 'learning_rate': 0.001563057658262979}. Best is trial 12 with value: 0.847457627118644.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 01:28, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:34:35,089] Trial 13 finished with value: 0.8203389830508474 and parameters: {'num_train_epochs': 5, 'per_device_train_batch_size': 64, 'warmup_steps': 117, 'weight_decay': 0.040528565735494876, 'learning_rate': 0.0011243495127365526}. Best is trial 12 with value: 0.847457627118644.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='88' max='88' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [88/88 01:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:35:50,747] Trial 14 finished with value: 0.7932203389830509 and parameters: {'num_train_epochs': 4, 'per_device_train_batch_size': 64, 'warmup_steps': 210, 'weight_decay': 0.0436981404230062, 'learning_rate': 0.007770263469183684}. Best is trial 12 with value: 0.847457627118644.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [344/344 01:28, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.533000</td>\n",
       "      <td>0.451679</td>\n",
       "      <td>0.844068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:37:24,430] Trial 15 finished with value: 0.847457627118644 and parameters: {'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'warmup_steps': 64, 'weight_decay': 0.07319688927984164, 'learning_rate': 0.0017434571888229327}. Best is trial 12 with value: 0.847457627118644.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [344/344 01:28, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.661400</td>\n",
       "      <td>0.534650</td>\n",
       "      <td>0.786441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:38:57,014] Trial 16 finished with value: 0.8 and parameters: {'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'warmup_steps': 114, 'weight_decay': 0.07420377247352274, 'learning_rate': 0.0003789009741885353}. Best is trial 12 with value: 0.847457627118644.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:21, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:39:23,562] Trial 17 finished with value: 0.7796610169491526 and parameters: {'num_train_epochs': 1, 'per_device_train_batch_size': 16, 'warmup_steps': 72, 'weight_decay': 0.07226682160699228, 'learning_rate': 0.0009866176116726621}. Best is trial 12 with value: 0.847457627118644.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [258/258 01:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.713500</td>\n",
       "      <td>0.595898</td>\n",
       "      <td>0.793220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:40:34,912] Trial 18 finished with value: 0.7898305084745763 and parameters: {'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'warmup_steps': 183, 'weight_decay': 0.04466878791057916, 'learning_rate': 0.00019468942253228117}. Best is trial 12 with value: 0.847457627118644.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='430' max='430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [430/430 01:49, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.684300</td>\n",
       "      <td>0.516456</td>\n",
       "      <td>0.796610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:42:29,457] Trial 19 finished with value: 0.8169491525423729 and parameters: {'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'warmup_steps': 261, 'weight_decay': 0.035151870447208994, 'learning_rate': 0.0005860381454718034}. Best is trial 12 with value: 0.847457627118644.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='301' max='301' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [301/301 02:16, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.498000</td>\n",
       "      <td>0.412760</td>\n",
       "      <td>0.833898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:44:50,920] Trial 20 finished with value: 0.8542372881355932 and parameters: {'num_train_epochs': 7, 'per_device_train_batch_size': 32, 'warmup_steps': 82, 'weight_decay': 0.050534541430133535, 'learning_rate': 0.0015626889733172966}. Best is trial 20 with value: 0.8542372881355932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='301' max='301' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [301/301 02:16, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.497800</td>\n",
       "      <td>0.443903</td>\n",
       "      <td>0.820339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:47:12,184] Trial 21 finished with value: 0.8338983050847457 and parameters: {'num_train_epochs': 7, 'per_device_train_batch_size': 32, 'warmup_steps': 83, 'weight_decay': 0.048982663250162095, 'learning_rate': 0.0015491344058346092}. Best is trial 20 with value: 0.8542372881355932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='301' max='301' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [301/301 02:16, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.502600</td>\n",
       "      <td>0.453424</td>\n",
       "      <td>0.837288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:49:33,605] Trial 22 finished with value: 0.8508474576271187 and parameters: {'num_train_epochs': 7, 'per_device_train_batch_size': 32, 'warmup_steps': 156, 'weight_decay': 0.06815079218801787, 'learning_rate': 0.004713224482642352}. Best is trial 20 with value: 0.8542372881355932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [344/344 02:36, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.499400</td>\n",
       "      <td>0.448787</td>\n",
       "      <td>0.827119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:52:14,894] Trial 23 finished with value: 0.8305084745762712 and parameters: {'num_train_epochs': 8, 'per_device_train_batch_size': 32, 'warmup_steps': 157, 'weight_decay': 0.049206201111705296, 'learning_rate': 0.00424263180439193}. Best is trial 20 with value: 0.8542372881355932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='301' max='301' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [301/301 02:16, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.418600</td>\n",
       "      <td>0.474839</td>\n",
       "      <td>0.820339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:54:36,041] Trial 24 finished with value: 0.8372881355932204 and parameters: {'num_train_epochs': 7, 'per_device_train_batch_size': 32, 'warmup_steps': 1, 'weight_decay': 0.03269497948250701, 'learning_rate': 0.004319340987712404}. Best is trial 20 with value: 0.8542372881355932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [344/344 02:35, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.529800</td>\n",
       "      <td>0.593270</td>\n",
       "      <td>0.806780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 14:57:16,820] Trial 25 finished with value: 0.8271186440677966 and parameters: {'num_train_epochs': 8, 'per_device_train_batch_size': 32, 'warmup_steps': 239, 'weight_decay': 0.09919164784952968, 'learning_rate': 0.008781033834690205}. Best is trial 20 with value: 0.8542372881355932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='387' max='387' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [387/387 02:55, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.486700</td>\n",
       "      <td>0.479217</td>\n",
       "      <td>0.830508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:00:16,701] Trial 26 finished with value: 0.8338983050847457 and parameters: {'num_train_epochs': 9, 'per_device_train_batch_size': 32, 'warmup_steps': 139, 'weight_decay': 0.06617965590492522, 'learning_rate': 0.004113527786603918}. Best is trial 20 with value: 0.8542372881355932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='301' max='301' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [301/301 02:16, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.510700</td>\n",
       "      <td>0.423699</td>\n",
       "      <td>0.840678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:02:37,692] Trial 27 finished with value: 0.8508474576271187 and parameters: {'num_train_epochs': 7, 'per_device_train_batch_size': 32, 'warmup_steps': 84, 'weight_decay': 0.05471679062278576, 'learning_rate': 0.0013323560104672118}. Best is trial 20 with value: 0.8542372881355932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='301' max='301' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [301/301 02:16, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.553400</td>\n",
       "      <td>0.446436</td>\n",
       "      <td>0.833898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:04:59,378] Trial 28 finished with value: 0.8305084745762712 and parameters: {'num_train_epochs': 7, 'per_device_train_batch_size': 32, 'warmup_steps': 105, 'weight_decay': 0.052799311997308127, 'learning_rate': 0.0007771235499745618}. Best is trial 20 with value: 0.8542372881355932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='387' max='387' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [387/387 02:55, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.579600</td>\n",
       "      <td>0.440440</td>\n",
       "      <td>0.830508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:07:59,770] Trial 29 finished with value: 0.8576271186440678 and parameters: {'num_train_epochs': 9, 'per_device_train_batch_size': 32, 'warmup_steps': 210, 'weight_decay': 0.07830680597137599, 'learning_rate': 0.0010710659975038334}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='430' max='430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [430/430 03:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.655800</td>\n",
       "      <td>0.506375</td>\n",
       "      <td>0.813559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:11:19,459] Trial 30 finished with value: 0.8305084745762712 and parameters: {'num_train_epochs': 10, 'per_device_train_batch_size': 32, 'warmup_steps': 295, 'weight_decay': 0.08076634354748458, 'learning_rate': 0.0004559277898826445}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='387' max='387' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [387/387 02:55, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.581000</td>\n",
       "      <td>0.514589</td>\n",
       "      <td>0.793220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:14:20,074] Trial 31 finished with value: 0.847457627118644 and parameters: {'num_train_epochs': 9, 'per_device_train_batch_size': 32, 'warmup_steps': 219, 'weight_decay': 0.06595275278856609, 'learning_rate': 0.0010501427277445235}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [344/344 02:35, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>0.478292</td>\n",
       "      <td>0.827119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:17:00,349] Trial 32 finished with value: 0.847457627118644 and parameters: {'num_train_epochs': 8, 'per_device_train_batch_size': 32, 'warmup_steps': 173, 'weight_decay': 0.060478100667010155, 'learning_rate': 0.0005744167391261727}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='301' max='301' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [301/301 02:16, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.544200</td>\n",
       "      <td>0.448590</td>\n",
       "      <td>0.837288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:19:22,738] Trial 33 finished with value: 0.8372881355932204 and parameters: {'num_train_epochs': 7, 'per_device_train_batch_size': 32, 'warmup_steps': 145, 'weight_decay': 0.07948952365077948, 'learning_rate': 0.0013234870280065183}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [258/258 01:57, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.525449</td>\n",
       "      <td>0.796610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:21:26,131] Trial 34 finished with value: 0.7932203389830509 and parameters: {'num_train_epochs': 6, 'per_device_train_batch_size': 32, 'warmup_steps': 186, 'weight_decay': 0.06482885404944655, 'learning_rate': 0.00024758895171403254}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='387' max='387' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [387/387 02:55, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.540700</td>\n",
       "      <td>0.436181</td>\n",
       "      <td>0.827119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:24:26,748] Trial 35 finished with value: 0.8372881355932204 and parameters: {'num_train_epochs': 9, 'per_device_train_batch_size': 32, 'warmup_steps': 94, 'weight_decay': 0.05437898403946771, 'learning_rate': 0.0008672425553303243}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [344/344 02:35, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.459900</td>\n",
       "      <td>0.439533</td>\n",
       "      <td>0.820339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:27:07,307] Trial 36 finished with value: 0.8305084745762712 and parameters: {'num_train_epochs': 8, 'per_device_train_batch_size': 32, 'warmup_steps': 39, 'weight_decay': 0.06944802891236256, 'learning_rate': 0.0020717186109463484}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [258/258 01:57, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.538500</td>\n",
       "      <td>0.486396</td>\n",
       "      <td>0.796610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:29:10,164] Trial 37 finished with value: 0.8169491525423729 and parameters: {'num_train_epochs': 6, 'per_device_train_batch_size': 32, 'warmup_steps': 266, 'weight_decay': 0.059883387437752, 'learning_rate': 0.0031763216600595007}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1720' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1720/1720 05:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.626400</td>\n",
       "      <td>0.532826</td>\n",
       "      <td>0.796610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.475600</td>\n",
       "      <td>0.596939</td>\n",
       "      <td>0.803390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.362200</td>\n",
       "      <td>0.479095</td>\n",
       "      <td>0.813559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.293300</td>\n",
       "      <td>0.494607</td>\n",
       "      <td>0.827119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.242500</td>\n",
       "      <td>0.537768</td>\n",
       "      <td>0.813559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.175600</td>\n",
       "      <td>0.471273</td>\n",
       "      <td>0.837288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:34:27,351] Trial 38 finished with value: 0.8372881355932204 and parameters: {'num_train_epochs': 10, 'per_device_train_batch_size': 8, 'warmup_steps': 134, 'weight_decay': 0.08192142004567379, 'learning_rate': 0.0017344846346965114}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='387' max='387' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [387/387 02:55, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.528500</td>\n",
       "      <td>0.476187</td>\n",
       "      <td>0.823729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:37:28,390] Trial 39 finished with value: 0.8271186440677966 and parameters: {'num_train_epochs': 9, 'per_device_train_batch_size': 32, 'warmup_steps': 360, 'weight_decay': 0.06271065261551571, 'learning_rate': 0.00560494521976}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='301' max='301' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [301/301 02:17, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.523800</td>\n",
       "      <td>0.487018</td>\n",
       "      <td>0.810169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:39:51,271] Trial 40 finished with value: 0.8338983050847457 and parameters: {'num_train_epochs': 7, 'per_device_train_batch_size': 32, 'warmup_steps': 231, 'weight_decay': 0.05272124694737593, 'learning_rate': 0.0032961045775229004}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 01:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:41:26,897] Trial 41 finished with value: 0.823728813559322 and parameters: {'num_train_epochs': 5, 'per_device_train_batch_size': 64, 'warmup_steps': 37, 'weight_decay': 0.04861979186757601, 'learning_rate': 0.0013550535933686523}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:47, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:43:21,218] Trial 42 finished with value: 0.8440677966101695 and parameters: {'num_train_epochs': 6, 'per_device_train_batch_size': 64, 'warmup_steps': 56, 'weight_decay': 0.000596843650938636, 'learning_rate': 0.0017260738331816828}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='860' max='860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [860/860 02:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.647300</td>\n",
       "      <td>0.545149</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.503400</td>\n",
       "      <td>0.492159</td>\n",
       "      <td>0.827119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.345600</td>\n",
       "      <td>0.443406</td>\n",
       "      <td>0.844068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:46:05,532] Trial 43 finished with value: 0.8271186440677966 and parameters: {'num_train_epochs': 5, 'per_device_train_batch_size': 8, 'warmup_steps': 201, 'weight_decay': 0.05668021917249309, 'learning_rate': 0.002299662625750226}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:47:04,614] Trial 44 finished with value: 0.7694915254237288 and parameters: {'num_train_epochs': 3, 'per_device_train_batch_size': 64, 'warmup_steps': 89, 'weight_decay': 0.05941868221855476, 'learning_rate': 0.0007524871712930556}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [344/344 02:36, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.484100</td>\n",
       "      <td>0.411561</td>\n",
       "      <td>0.850847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:49:45,898] Trial 45 finished with value: 0.847457627118644 and parameters: {'num_train_epochs': 8, 'per_device_train_batch_size': 32, 'warmup_steps': 24, 'weight_decay': 0.040334013509401564, 'learning_rate': 0.0011729531362079026}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:46, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:51:37,935] Trial 46 finished with value: 0.8169491525423729 and parameters: {'num_train_epochs': 6, 'per_device_train_batch_size': 64, 'warmup_steps': 165, 'weight_decay': 0.06867536029652702, 'learning_rate': 0.006297839406171058}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1204' max='1204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1204/1204 03:37, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.638100</td>\n",
       "      <td>0.466574</td>\n",
       "      <td>0.830508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.504100</td>\n",
       "      <td>0.467573</td>\n",
       "      <td>0.827119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.458472</td>\n",
       "      <td>0.830508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.268100</td>\n",
       "      <td>0.472788</td>\n",
       "      <td>0.840678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:55:19,604] Trial 47 finished with value: 0.8406779661016949 and parameters: {'num_train_epochs': 7, 'per_device_train_batch_size': 8, 'warmup_steps': 123, 'weight_decay': 0.06211821706491504, 'learning_rate': 0.0027774770952546375}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='215' max='215' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [215/215 01:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:57:02,251] Trial 48 finished with value: 0.8305084745762712 and parameters: {'num_train_epochs': 5, 'per_device_train_batch_size': 32, 'warmup_steps': 50, 'weight_decay': 0.07524678690313377, 'learning_rate': 0.002384474651380229}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 02:23, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 15:59:31,674] Trial 49 finished with value: 0.8542372881355932 and parameters: {'num_train_epochs': 8, 'per_device_train_batch_size': 64, 'warmup_steps': 70, 'weight_decay': 0.05322090685793005, 'learning_rate': 0.0019027491153365656}. Best is trial 29 with value: 0.8576271186440678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization Results:\n",
      "Trial 1:\n",
      "  Value (Accuracy): 0.7288135593220338\n",
      "  Params: {'num_train_epochs': 10, 'per_device_train_batch_size': 64, 'warmup_steps': 416, 'weight_decay': 0.0864178182365929, 'learning_rate': 4.006946584754387e-05}\n",
      "---------------------------\n",
      "Trial 2:\n",
      "  Value (Accuracy): 0.7864406779661017\n",
      "  Params: {'num_train_epochs': 6, 'per_device_train_batch_size': 16, 'warmup_steps': 178, 'weight_decay': 0.05953659664645361, 'learning_rate': 0.00011849058183535206}\n",
      "---------------------------\n",
      "Trial 3:\n",
      "  Value (Accuracy): 0.7220338983050848\n",
      "  Params: {'num_train_epochs': 2, 'per_device_train_batch_size': 8, 'warmup_steps': 119, 'weight_decay': 0.026570422078083133, 'learning_rate': 1.9273357280023197e-05}\n",
      "---------------------------\n",
      "Trial 4:\n",
      "  Value (Accuracy): 0.7966101694915254\n",
      "  Params: {'num_train_epochs': 9, 'per_device_train_batch_size': 8, 'warmup_steps': 35, 'weight_decay': 0.010844831774157916, 'learning_rate': 6.767340190117872e-05}\n",
      "---------------------------\n",
      "Trial 5:\n",
      "  Value (Accuracy): 0.8101694915254237\n",
      "  Params: {'num_train_epochs': 2, 'per_device_train_batch_size': 8, 'warmup_steps': 451, 'weight_decay': 0.022720293054870666, 'learning_rate': 0.000693522105434715}\n",
      "---------------------------\n",
      "Trial 6:\n",
      "  Value (Accuracy): 0.7559322033898305\n",
      "  Params: {'num_train_epochs': 2, 'per_device_train_batch_size': 8, 'warmup_steps': 317, 'weight_decay': 0.02136262824388965, 'learning_rate': 0.0001013144918873407}\n",
      "---------------------------\n",
      "Trial 7:\n",
      "  Value (Accuracy): 0.8372881355932204\n",
      "  Params: {'num_train_epochs': 7, 'per_device_train_batch_size': 64, 'warmup_steps': 50, 'weight_decay': 0.06290031023039559, 'learning_rate': 0.0023661656003565383}\n",
      "---------------------------\n",
      "Trial 8:\n",
      "  Value (Accuracy): 0.735593220338983\n",
      "  Params: {'num_train_epochs': 10, 'per_device_train_batch_size': 32, 'warmup_steps': 323, 'weight_decay': 0.08995642429250524, 'learning_rate': 1.7017878712098978e-05}\n",
      "---------------------------\n",
      "Trial 9:\n",
      "  Value (Accuracy): 0.7084745762711865\n",
      "  Params: {'num_train_epochs': 4, 'per_device_train_batch_size': 8, 'warmup_steps': 480, 'weight_decay': 0.008707000793174813, 'learning_rate': 0.006649994678744354}\n",
      "---------------------------\n",
      "Trial 10:\n",
      "  Value (Accuracy): 0.8033898305084746\n",
      "  Params: {'num_train_epochs': 8, 'per_device_train_batch_size': 32, 'warmup_steps': 416, 'weight_decay': 0.09149230988250258, 'learning_rate': 0.0003429655698153725}\n",
      "---------------------------\n",
      "Trial 11:\n",
      "  Value (Accuracy): 0.8440677966101695\n",
      "  Params: {'num_train_epochs': 6, 'per_device_train_batch_size': 64, 'warmup_steps': 15, 'weight_decay': 0.056417565762603525, 'learning_rate': 0.0025972802613795243}\n",
      "---------------------------\n",
      "Trial 12:\n",
      "  Value (Accuracy): 0.8406779661016949\n",
      "  Params: {'num_train_epochs': 6, 'per_device_train_batch_size': 64, 'warmup_steps': 6, 'weight_decay': 0.057167535327949846, 'learning_rate': 0.0026892793271674504}\n",
      "---------------------------\n",
      "Trial 13:\n",
      "  Value (Accuracy): 0.847457627118644\n",
      "  Params: {'num_train_epochs': 5, 'per_device_train_batch_size': 64, 'warmup_steps': 2, 'weight_decay': 0.044354486614017856, 'learning_rate': 0.001563057658262979}\n",
      "---------------------------\n",
      "Trial 14:\n",
      "  Value (Accuracy): 0.8203389830508474\n",
      "  Params: {'num_train_epochs': 5, 'per_device_train_batch_size': 64, 'warmup_steps': 117, 'weight_decay': 0.040528565735494876, 'learning_rate': 0.0011243495127365526}\n",
      "---------------------------\n",
      "Trial 15:\n",
      "  Value (Accuracy): 0.7932203389830509\n",
      "  Params: {'num_train_epochs': 4, 'per_device_train_batch_size': 64, 'warmup_steps': 210, 'weight_decay': 0.0436981404230062, 'learning_rate': 0.007770263469183684}\n",
      "---------------------------\n",
      "Trial 16:\n",
      "  Value (Accuracy): 0.847457627118644\n",
      "  Params: {'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'warmup_steps': 64, 'weight_decay': 0.07319688927984164, 'learning_rate': 0.0017434571888229327}\n",
      "---------------------------\n",
      "Trial 17:\n",
      "  Value (Accuracy): 0.8\n",
      "  Params: {'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'warmup_steps': 114, 'weight_decay': 0.07420377247352274, 'learning_rate': 0.0003789009741885353}\n",
      "---------------------------\n",
      "Trial 18:\n",
      "  Value (Accuracy): 0.7796610169491526\n",
      "  Params: {'num_train_epochs': 1, 'per_device_train_batch_size': 16, 'warmup_steps': 72, 'weight_decay': 0.07226682160699228, 'learning_rate': 0.0009866176116726621}\n",
      "---------------------------\n",
      "Trial 19:\n",
      "  Value (Accuracy): 0.7898305084745763\n",
      "  Params: {'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'warmup_steps': 183, 'weight_decay': 0.04466878791057916, 'learning_rate': 0.00019468942253228117}\n",
      "---------------------------\n",
      "Trial 20:\n",
      "  Value (Accuracy): 0.8169491525423729\n",
      "  Params: {'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'warmup_steps': 261, 'weight_decay': 0.035151870447208994, 'learning_rate': 0.0005860381454718034}\n",
      "---------------------------\n",
      "Trial 21:\n",
      "  Value (Accuracy): 0.8542372881355932\n",
      "  Params: {'num_train_epochs': 7, 'per_device_train_batch_size': 32, 'warmup_steps': 82, 'weight_decay': 0.050534541430133535, 'learning_rate': 0.0015626889733172966}\n",
      "---------------------------\n",
      "Trial 22:\n",
      "  Value (Accuracy): 0.8338983050847457\n",
      "  Params: {'num_train_epochs': 7, 'per_device_train_batch_size': 32, 'warmup_steps': 83, 'weight_decay': 0.048982663250162095, 'learning_rate': 0.0015491344058346092}\n",
      "---------------------------\n",
      "Trial 23:\n",
      "  Value (Accuracy): 0.8508474576271187\n",
      "  Params: {'num_train_epochs': 7, 'per_device_train_batch_size': 32, 'warmup_steps': 156, 'weight_decay': 0.06815079218801787, 'learning_rate': 0.004713224482642352}\n",
      "---------------------------\n",
      "Trial 24:\n",
      "  Value (Accuracy): 0.8305084745762712\n",
      "  Params: {'num_train_epochs': 8, 'per_device_train_batch_size': 32, 'warmup_steps': 157, 'weight_decay': 0.049206201111705296, 'learning_rate': 0.00424263180439193}\n",
      "---------------------------\n",
      "Trial 25:\n",
      "  Value (Accuracy): 0.8372881355932204\n",
      "  Params: {'num_train_epochs': 7, 'per_device_train_batch_size': 32, 'warmup_steps': 1, 'weight_decay': 0.03269497948250701, 'learning_rate': 0.004319340987712404}\n",
      "---------------------------\n",
      "Trial 26:\n",
      "  Value (Accuracy): 0.8271186440677966\n",
      "  Params: {'num_train_epochs': 8, 'per_device_train_batch_size': 32, 'warmup_steps': 239, 'weight_decay': 0.09919164784952968, 'learning_rate': 0.008781033834690205}\n",
      "---------------------------\n",
      "Trial 27:\n",
      "  Value (Accuracy): 0.8338983050847457\n",
      "  Params: {'num_train_epochs': 9, 'per_device_train_batch_size': 32, 'warmup_steps': 139, 'weight_decay': 0.06617965590492522, 'learning_rate': 0.004113527786603918}\n",
      "---------------------------\n",
      "Trial 28:\n",
      "  Value (Accuracy): 0.8508474576271187\n",
      "  Params: {'num_train_epochs': 7, 'per_device_train_batch_size': 32, 'warmup_steps': 84, 'weight_decay': 0.05471679062278576, 'learning_rate': 0.0013323560104672118}\n",
      "---------------------------\n",
      "Trial 29:\n",
      "  Value (Accuracy): 0.8305084745762712\n",
      "  Params: {'num_train_epochs': 7, 'per_device_train_batch_size': 32, 'warmup_steps': 105, 'weight_decay': 0.052799311997308127, 'learning_rate': 0.0007771235499745618}\n",
      "---------------------------\n",
      "Trial 30:\n",
      "  Value (Accuracy): 0.8576271186440678\n",
      "  Params: {'num_train_epochs': 9, 'per_device_train_batch_size': 32, 'warmup_steps': 210, 'weight_decay': 0.07830680597137599, 'learning_rate': 0.0010710659975038334}\n",
      "---------------------------\n",
      "Trial 31:\n",
      "  Value (Accuracy): 0.8305084745762712\n",
      "  Params: {'num_train_epochs': 10, 'per_device_train_batch_size': 32, 'warmup_steps': 295, 'weight_decay': 0.08076634354748458, 'learning_rate': 0.0004559277898826445}\n",
      "---------------------------\n",
      "Trial 32:\n",
      "  Value (Accuracy): 0.847457627118644\n",
      "  Params: {'num_train_epochs': 9, 'per_device_train_batch_size': 32, 'warmup_steps': 219, 'weight_decay': 0.06595275278856609, 'learning_rate': 0.0010501427277445235}\n",
      "---------------------------\n",
      "Trial 33:\n",
      "  Value (Accuracy): 0.847457627118644\n",
      "  Params: {'num_train_epochs': 8, 'per_device_train_batch_size': 32, 'warmup_steps': 173, 'weight_decay': 0.060478100667010155, 'learning_rate': 0.0005744167391261727}\n",
      "---------------------------\n",
      "Trial 34:\n",
      "  Value (Accuracy): 0.8372881355932204\n",
      "  Params: {'num_train_epochs': 7, 'per_device_train_batch_size': 32, 'warmup_steps': 145, 'weight_decay': 0.07948952365077948, 'learning_rate': 0.0013234870280065183}\n",
      "---------------------------\n",
      "Trial 35:\n",
      "  Value (Accuracy): 0.7932203389830509\n",
      "  Params: {'num_train_epochs': 6, 'per_device_train_batch_size': 32, 'warmup_steps': 186, 'weight_decay': 0.06482885404944655, 'learning_rate': 0.00024758895171403254}\n",
      "---------------------------\n",
      "Trial 36:\n",
      "  Value (Accuracy): 0.8372881355932204\n",
      "  Params: {'num_train_epochs': 9, 'per_device_train_batch_size': 32, 'warmup_steps': 94, 'weight_decay': 0.05437898403946771, 'learning_rate': 0.0008672425553303243}\n",
      "---------------------------\n",
      "Trial 37:\n",
      "  Value (Accuracy): 0.8305084745762712\n",
      "  Params: {'num_train_epochs': 8, 'per_device_train_batch_size': 32, 'warmup_steps': 39, 'weight_decay': 0.06944802891236256, 'learning_rate': 0.0020717186109463484}\n",
      "---------------------------\n",
      "Trial 38:\n",
      "  Value (Accuracy): 0.8169491525423729\n",
      "  Params: {'num_train_epochs': 6, 'per_device_train_batch_size': 32, 'warmup_steps': 266, 'weight_decay': 0.059883387437752, 'learning_rate': 0.0031763216600595007}\n",
      "---------------------------\n",
      "Trial 39:\n",
      "  Value (Accuracy): 0.8372881355932204\n",
      "  Params: {'num_train_epochs': 10, 'per_device_train_batch_size': 8, 'warmup_steps': 134, 'weight_decay': 0.08192142004567379, 'learning_rate': 0.0017344846346965114}\n",
      "---------------------------\n",
      "Trial 40:\n",
      "  Value (Accuracy): 0.8271186440677966\n",
      "  Params: {'num_train_epochs': 9, 'per_device_train_batch_size': 32, 'warmup_steps': 360, 'weight_decay': 0.06271065261551571, 'learning_rate': 0.00560494521976}\n",
      "---------------------------\n",
      "Trial 41:\n",
      "  Value (Accuracy): 0.8338983050847457\n",
      "  Params: {'num_train_epochs': 7, 'per_device_train_batch_size': 32, 'warmup_steps': 231, 'weight_decay': 0.05272124694737593, 'learning_rate': 0.0032961045775229004}\n",
      "---------------------------\n",
      "Trial 42:\n",
      "  Value (Accuracy): 0.823728813559322\n",
      "  Params: {'num_train_epochs': 5, 'per_device_train_batch_size': 64, 'warmup_steps': 37, 'weight_decay': 0.04861979186757601, 'learning_rate': 0.0013550535933686523}\n",
      "---------------------------\n",
      "Trial 43:\n",
      "  Value (Accuracy): 0.8440677966101695\n",
      "  Params: {'num_train_epochs': 6, 'per_device_train_batch_size': 64, 'warmup_steps': 56, 'weight_decay': 0.000596843650938636, 'learning_rate': 0.0017260738331816828}\n",
      "---------------------------\n",
      "Trial 44:\n",
      "  Value (Accuracy): 0.8271186440677966\n",
      "  Params: {'num_train_epochs': 5, 'per_device_train_batch_size': 8, 'warmup_steps': 201, 'weight_decay': 0.05668021917249309, 'learning_rate': 0.002299662625750226}\n",
      "---------------------------\n",
      "Trial 45:\n",
      "  Value (Accuracy): 0.7694915254237288\n",
      "  Params: {'num_train_epochs': 3, 'per_device_train_batch_size': 64, 'warmup_steps': 89, 'weight_decay': 0.05941868221855476, 'learning_rate': 0.0007524871712930556}\n",
      "---------------------------\n",
      "Trial 46:\n",
      "  Value (Accuracy): 0.847457627118644\n",
      "  Params: {'num_train_epochs': 8, 'per_device_train_batch_size': 32, 'warmup_steps': 24, 'weight_decay': 0.040334013509401564, 'learning_rate': 0.0011729531362079026}\n",
      "---------------------------\n",
      "Trial 47:\n",
      "  Value (Accuracy): 0.8169491525423729\n",
      "  Params: {'num_train_epochs': 6, 'per_device_train_batch_size': 64, 'warmup_steps': 165, 'weight_decay': 0.06867536029652702, 'learning_rate': 0.006297839406171058}\n",
      "---------------------------\n",
      "Trial 48:\n",
      "  Value (Accuracy): 0.8406779661016949\n",
      "  Params: {'num_train_epochs': 7, 'per_device_train_batch_size': 8, 'warmup_steps': 123, 'weight_decay': 0.06211821706491504, 'learning_rate': 0.0027774770952546375}\n",
      "---------------------------\n",
      "Trial 49:\n",
      "  Value (Accuracy): 0.8305084745762712\n",
      "  Params: {'num_train_epochs': 5, 'per_device_train_batch_size': 32, 'warmup_steps': 50, 'weight_decay': 0.07524678690313377, 'learning_rate': 0.002384474651380229}\n",
      "---------------------------\n",
      "Trial 50:\n",
      "  Value (Accuracy): 0.8542372881355932\n",
      "  Params: {'num_train_epochs': 8, 'per_device_train_batch_size': 64, 'warmup_steps': 70, 'weight_decay': 0.05322090685793005, 'learning_rate': 0.0019027491153365656}\n",
      "---------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 5. Train with the best parameters\u001b[39;00m\n\u001b[1;32m     29\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[0;32m---> 30\u001b[0m trainer \u001b[38;5;241m=\u001b[39m train_with_best_params(train_dataset_t, val_dataset,\u001b[43mmodel_t\u001b[49m, best_params)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Save the model after optimization\u001b[39;00m\n\u001b[1;32m     33\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_after_optimization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_t' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Initialize model and tokenizer\n",
    "tokenizer, model = initialize_model_and_tokenizer()\n",
    "\n",
    "# 2. Process your dataframe\n",
    "processed_df = process_dataframe(processed_df)  # Assuming the dataframe is named 'processed_df'\n",
    "\n",
    "# 3. Prepare the dataset\n",
    "df_sample = processed_df.sample(frac=0.25, random_state=5)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df_sample['Target'].values)\n",
    "X = df_sample['Headlines'].values\n",
    "\n",
    "train_dataset, val_dataset, test_dataset, y_true = prepare_dataset(X, y, tokenizer)\n",
    "\n",
    "y_t = label_encoder.fit_transform(processed_df['Target'].values)\n",
    "X_t = processed_df['Headlines'].values\n",
    "\n",
    "train_dataset_t, val_dataset_t, test_dataset_t, y_true_t = prepare_dataset(X_t, y_t, tokenizer)\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained('ProsusAI/finbert')\n",
    "\n",
    "# 4. Optimize hyperparameters using Optuna\n",
    "study = optimize_hyperparameters(train_dataset, val_dataset, model_init)\n",
    "print_study_results(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cff4575e-bc19-4307-af52-d0acc08d731e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is running on: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulvij/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1548' max='1548' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1548/1548 13:48, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.595600</td>\n",
       "      <td>0.495973</td>\n",
       "      <td>0.798134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.425600</td>\n",
       "      <td>0.434460</td>\n",
       "      <td>0.826972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.360300</td>\n",
       "      <td>0.419629</td>\n",
       "      <td>0.842239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.320300</td>\n",
       "      <td>0.409100</td>\n",
       "      <td>0.844784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.294700</td>\n",
       "      <td>0.416176</td>\n",
       "      <td>0.844784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.282000</td>\n",
       "      <td>0.419457</td>\n",
       "      <td>0.842239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with Best Parameters:\n",
      "Evaluation Loss: 0.40909987688064575\n",
      "Evaluation Accuracy: 0.8447837150127226\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA0KklEQVR4nO3deXhV5bn38e+dgSQkAQIJYwIJIYDMQ0RlMggqjjhghVIVbRnE2dNW27ettrbHntZjPVZRccCqKKIWitWClTKKCmEmTEIIEBAICCEBQqb7/WOvhJ24Q6a9szPcn+vKlew17XszrF/Ws571PKKqGGOMMeUF+LsAY4wx9ZMFhDHGGI8sIIwxxnhkAWGMMcYjCwhjjDEeBfm7AG+Kjo7W+Ph4f5dhjDENxrp1646paoyndY0qIOLj40lNTfV3GcYY02CIyL6K1lkTkzHGGI8sIIwxxnjk04AQkbEislNEdovI4xVskyIiG0UkTUSWV2dfY4wxvuOzexAiEgi8CFwJZAJrRWShqm5z26YVMBMYq6r7RaRtVfc1xvhPQUEBmZmZ5OXl+bsUU0WhoaHExsYSHBxc5X18eZN6CLBbVdMBRGQuMA5wP8n/EPi7qu4HUNWj1djXGOMnmZmZREZGEh8fj4j4uxxTCVXl+PHjZGZmkpCQUOX9fNnE1Ak44PY601nmrjsQJSLLRGSdiNxZjX0BEJGpIpIqIqlZWVleKt0YcyF5eXm0adPGwqGBEBHatGlT7Ss+X15BePqXU37o2CBgMDAaCAO+FJGvqriva6HqLGAWQHJysg1Na0wdsXBoWGry9+XLK4hMIM7tdSxwyMM2i1T1tKoeA1YA/au4r1fkFRQxa8Uevk4/7ovDG2NMg+XLgFgLJIlIgog0AyYAC8tt8w9ghIgEiUhz4BJgexX39QoReH3VXp77/BtfHN4Y4wPHjx9nwIABDBgwgPbt29OpU6fS1/n5+RfcNzU1lQcffLDS9xg6dKhXal22bBnXX3+9V45V13zWxKSqhSJyP7AYCATeUNU0EZnurH9ZVbeLyCJgM1AMvKaqWwE87euLOkOCApkyoiu//2Q7G/afYGDnKF+8jTHGi9q0acPGjRsBePLJJ4mIiOCnP/1p6frCwkKCgjyf3pKTk0lOTq70PVavXu2VWhsynz4Hoaqfqmp3VU1U1T84y15W1ZfdtvmzqvZS1T6q+tyF9vWViUM606p5MDOX7fHl2xhjfGjy5Mk8+uijjBo1iscee4w1a9YwdOhQBg4cyNChQ9m5cydQ9jf6J598knvuuYeUlBS6du3K888/X3q8iIiI0u1TUlIYP348PXv2ZNKkSZTMxPnpp5/Ss2dPhg8fzoMPPlitK4X33nuPvn370qdPHx577DEAioqKmDx5Mn369KFv37785S9/AeD555+nV69e9OvXjwkTJtT+D6uKGtVYTDUVHhLEXZfF839LvmHXkRy6t4v0d0nGNBi//TiNbYdOefWYvTq24Ikbeld7v127dvH5558TGBjIqVOnWLFiBUFBQXz++ef88pe/5KOPPvrePjt27GDp0qXk5OTQo0cP7r333u89K7BhwwbS0tLo2LEjw4YN44svviA5OZlp06axYsUKEhISmDhxYpXrPHToEI899hjr1q0jKiqKq666igULFhAXF8fBgwfZunUrACdPngTgj3/8I3v37iUkJKR0WV2woTYck4fG07xZIC/ZVYQxDdZtt91GYGAgANnZ2dx222306dOHRx55hLQ0z63U1113HSEhIURHR9O2bVuOHDnyvW2GDBlCbGwsAQEBDBgwgIyMDHbs2EHXrl1LnyuoTkCsXbuWlJQUYmJiCAoKYtKkSaxYsYKuXbuSnp7OAw88wKJFi2jRogUA/fr1Y9KkSbzzzjsVNp35gl1BOKLCmzFxSGfeXJ3Bo1d2J651c3+XZEyDUJPf9H0lPDy89Odf//rXjBo1ivnz55ORkUFKSorHfUJCQkp/DgwMpLCwsErblDQz1URF+0ZFRbFp0yYWL17Miy++yLx583jjjTf45JNPWLFiBQsXLuSpp54iLS2tToLCriDcTBnRlQCBWSvS/V2KMaaWsrOz6dTJ9Xztm2++6fXj9+zZk/T0dDIyMgB4//33q7zvJZdcwvLlyzl27BhFRUW89957XH755Rw7dozi4mJuvfVWnnrqKdavX09xcTEHDhxg1KhR/OlPf+LkyZPk5uZ6/fN4YlcQbtq3DOXWQbHMSz3Ag6OTiIkMqXwnY0y99POf/5y77rqLZ599liuuuMLrxw8LC2PmzJmMHTuW6OhohgwZUuG2S5YsITY2tvT1Bx98wNNPP82oUaNQVa699lrGjRvHpk2buPvuuykuLgbg6aefpqioiB/96EdkZ2ejqjzyyCO0atXK65/HE6nNZVJ9k5ycrLWdMGjvsdOM/t9lTLs8kcfG9vRSZcY0Ltu3b+eiiy7ydxl+l5ubS0REBKrKfffdR1JSEo888oi/y6qQp783EVmnqh77/VoTUzkJ0eFc07cDb3+5j+yzBf4uxxhTj7366qsMGDCA3r17k52dzbRp0/xdkldZQHhw7+WJ5J4r5J2vKpyJzxhjeOSRR9i4cSPbtm1jzpw5NG/euDq3WEB40KdTS1J6xPDGqr2czS/ydznGGOMXFhAVmJHSjeOn85mXeqDyjY0xphGygKjAkITWJHeJYtaKdAqKiv1djjHG1DkLiAuYMSqRgyfP8o+NPhlp3Bhj6jULiAsY1aMtPdtH8vLyPRQXN57uwMY0dCkpKSxevLjMsueee44ZM2ZccJ+SbvDXXnutxzGNnnzySZ555pkLvveCBQvYtu387Me/+c1v+Pzzz6tRvWf1cVhwC4gLEBFmjOrG7qO5fLbt++OzGGP8Y+LEicydO7fMsrlz51Z5PKRPP/20xg+blQ+I3/3ud4wZM6ZGx6rvLCAqcW2f9nRp05yXlu2u1dgrxhjvGT9+PP/85z85d+4cABkZGRw6dIjhw4dz7733kpycTO/evXniiSc87h8fH8+xY8cA+MMf/kCPHj0YM2ZM6ZDg4HrG4eKLL6Z///7ceuutnDlzhtWrV7Nw4UJ+9rOfMWDAAPbs2cPkyZP58MMPAdcT0wMHDqRv377cc889pfXFx8fzxBNPMGjQIPr27cuOHTuq/Fn9OSy4DbVRiaDAAKaNTOSX87ewes9xhnWL9ndJxtQv/3ocDm/x7jHb94Vr/ljh6jZt2jBkyBAWLVrEuHHjmDt3Lrfffjsiwh/+8Adat25NUVERo0ePZvPmzfTr18/jcdatW8fcuXPZsGEDhYWFDBo0iMGDBwNwyy23MGXKFAB+9atf8frrr/PAAw9w4403cv311zN+/Pgyx8rLy2Py5MksWbKE7t27c+edd/LSSy/x8MMPAxAdHc369euZOXMmzzzzDK+99lqlfwz+HhbcriCq4NbBnWgbGcKLS3f7uxRjjMO9mcm9eWnevHkMGjSIgQMHkpaWVqY5qLyVK1dy880307x5c1q0aMGNN95Yum7r1q2MGDGCvn37MmfOnAqHCy+xc+dOEhIS6N69OwB33XUXK1asKF1/yy23ADB48ODSAf4q4+9hwe0KogpCggL5yYgE/vvTHWw8cJIBca38XZIx9ccFftP3pZtuuolHH32U9evXc/bsWQYNGsTevXt55plnWLt2LVFRUUyePJm8vLwLHkdEPC6fPHkyCxYsoH///rz55pssW7bsgseprAm6ZMjwioYUr84x62pYcLuCqKIfXtKFlmHBzLSrCGPqhYiICFJSUrjnnntKrx5OnTpFeHg4LVu25MiRI/zrX/+64DFGjhzJ/PnzOXv2LDk5OXz88cel63JycujQoQMFBQXMmTOndHlkZCQ5OTnfO1bPnj3JyMhg927XOeLtt9/m8ssvr9Vn9Pew4HYFUUURIUHcNTSe55d8wzdHckiyaUmN8buJEydyyy23lDY19e/fn4EDB9K7d2+6du3KsGHDLrj/oEGDuP322xkwYABdunRhxIgRpeueeuopLrnkErp06ULfvn1LQ2HChAlMmTKF559/vvTmNEBoaCizZ8/mtttuo7CwkIsvvpjp06dX6/PUt2HBbbjvajhxOp+hf/wP1/Rtz7M/GOCz9zGmvrPhvhsmG+7bh0qmJf3HxkMc+O6Mv8sxxhifsoCopikjEwgQeHWlTUtqjGncfBoQIjJWRHaKyG4RedzD+hQRyRaRjc7Xb9zWZYjIFme579qNqqlDyzBuHtiJ99ceICvnnL/LMcZvGlPzdFNQk78vnwWEiAQCLwLXAL2AiSLSy8OmK1V1gPP1u3LrRjnLPbaP+cv0yxPJLypm9hd7/V2KMX4RGhrK8ePHLSQaCFXl+PHjhIaGVms/X/ZiGgLsVtV0ABGZC4wDKn5qpYHoGhPBtX1c05JOT0mkRWiwv0sypk7FxsaSmZlJVlaWv0sxVRQaGlqmh1RV+DIgOgHus+1kApd42O4yEdkEHAJ+qqoljysq8JmIKPCKqs7y9CYiMhWYCtC5c2dv1V6pe1MS+WTLt7zz1T5mpHSrs/c1pj4IDg4mISHB32UYH/PlPQhPjyeWvx5dD3RR1f7AX4EFbuuGqeogXE1U94nISE9voqqzVDVZVZNjYmK8UHbV9OnUkpHdXdOS5hXYtKTGmMbHlwGRCcS5vY7FdZVQSlVPqWqu8/OnQLCIRDuvDznfjwLzcTVZ1SszUhI5lmvTkhpjGidfBsRaIElEEkSkGTABWOi+gYi0F2cgFBEZ4tRzXETCRSTSWR4OXAVs9WGtNXJJQmsGd4nileU2LakxpvHxWUCoaiFwP7AY2A7MU9U0EZkuIiXPn48Htjr3IJ4HJqirW0Q7YJWzfA3wiaou8lWtNSUizEhxTUv68SabltQY07jYUBu1pKpc838rKSpWFj88koAAzyNDGmNMfWRDbfiQiHBvSiLfHM3l39ttWlJjTONhAeEF1/XtQOfWzZm5bI89OGSMaTQsILwgKDCAaZd3ZdOBk3y557i/yzHGGK+wgPCSWwfFEhMZwsxle/xdijHGeIUFhJeEBgfyk+EJrNp9jE0HTvq7HGOMqTULCC+adGkXWoQGMXOZTUtqjGn4LCC8qGRa0sVpR9h99Ptz1hpjTENiAeFldw9LICw4kJeW2YRCxpiGzQLCy1qHN2PCkDj+sfEgB0+e9Xc5xhhTYxYQPjBlRFdE4NUVdhVhjGm4LCB8oGOrMG4a0In31uznWK5NS2qMaZgsIHxkeopNS2qMadgsIHwkMSaCa/q0560v95GTV+DvcowxptosIHxoRko3cvIKeeer/f4uxRhjqs0Cwof6dGrJiKRoXrdpSY0xDZAFhI/NSOnGsdxzfGDTkhpjGhgLCB+7tGtrBnZuxSsr0im0aUmNMQ2IBYSPuaYl7UbmibN8vNmmJTXGNBwWEHVgdM+29GgXyUvL9lBcbBMKGWMaBguIOhAQ4JqWdNeRXJbsOOrvcowxpkosIOrI9f06ENc6jBeX7rZpSY0xDYIFRB0JCgxg6shENh44yZfpNi2pMab+82lAiMhYEdkpIrtF5HEP61NEJFtENjpfv6nqvg3RbYNjiY4I4SWbltQY0wD4LCBEJBB4EbgG6AVMFJFeHjZdqaoDnK/fVXPfBiU0OJCfjEhg5TfH2JKZ7e9yjDHmgnx5BTEE2K2q6aqaD8wFxtXBvvXapEs627SkxpgGwZcB0Qlwf3w401lW3mUisklE/iUivau5b4MTGRrMnZfFsyjtMLuP5vq7HGOMqZAvA0I8LCvffWc90EVV+wN/BRZUY1/XhiJTRSRVRFKzsrJqVmkd9yq6e1g8IUEBvLzc7kUYY+ovXwZEJhDn9joWKPMosaqeUtVc5+dPgWARia7Kvm7HmKWqyaqaHBMTU/0qi4tg7iTYNLf6+9ZQm4gQJlzcmQUbbFpSY0z95cuAWAskiUiCiDQDJgAL3TcQkfYiIs7PQ5x6jldlX685lwN52TB/Gnz8EBTk+eRtypsysitg05IaY+ovnwWEqhYC9wOLge3APFVNE5HpIjLd2Ww8sFVENgHPAxPUxeO+Pik0rBXc+Q8Y/gisexNevxK+8/0scJ1ahXHTwE7MXbuf4zYtqTGmHpLG9FRvcnKypqam1vwAOxfB/Kmuux03vwQ9r/NabZ7sPprLlX9Zzv2juvFfV/Xw6XsZY4wnIrJOVZM9rbMnqd31GAvTVkDrBJj7Q/js11Dku+lCu7WN4Ope7XlzdYZNS2qMqXcsIMqLiocffwYX/wRWPw9/uwFOfeuzt5sxKpGcvELmfG3Tkhpj6hcLCE+CQuC6/4VbXoNvN8MrIyB9mU/eql9sK5uW1BhTL1lAXEi/22DqUghrDW/fDMv/DMXenxXu3pREsnLO8eG6TK8f2xhjasoCojIxPWDKf6DPeFj6e3j3B3DmO6++xWVd2zAgrhWvrNhj05IaY+oNC4iqCImAW2bBdc/C3uXw8gjIrEVvqXJc05ImcuC7s/xzs+/udxhjTHVYQFSVCFz8Y9cN7IAAeGMsfP2K14bpGHNRO5LaRti0pMaYesMCoro6DnR1he02Gv71c/jwbtfT2LUUECDMGJXIziM5/MemJTXG1AMWEDURFgUT3oMxT8K2f8CsUXBkW60Pe0O/jsRGhTFzmU1LaozxPwuImgoIcA3PcdfHcO4UvHoFbHyvVocMCgxg2siurN9/kq/3evdGuDHGVJcFRG3FD4dpKyE2GRZMh4UP1mrAv9uS44iOaMaLS21CIWOMf1lAeENkO7hjAYz4L1j/N3h9DHxXs1FaQ4MDuWe4TUtqjPE/CwhvCQyC0b+BH86DkwfglRTY/s8aHepHl3YhMjSIl5bbVYQxxn8sILyt+9WuXk5tEuH9SbD4/1V7wL8WocHceVkX/rX1MHuybFpSY4x/WED4QlQXuGcRXDwFvnwB3rweTnmcEK9Cdw9LoFlgAK/YtKTGGD+xgPCVoBC47hm49XU4vMX19PWepVXePToihAkXxzF/w0EO2bSkxhg/sIDwtb7jXQP+hUc7A/79qcoD/k0Z2RVVeHWlTUtqjKl7FhB1oWTAv34/gKV/gDnj4fTxSneLjWrOjQM6MnfNAb47nV8HhRpjzHkWEHWlWTjc/Apc/xxkrHTNMXFgbaW7zUhJJK+wiDe/8P082cYY484Coi6JQPLd8ON/Q0AQzB4LX710wQH/urWN5Kpe7XhzdQa55wrrsFhjTFNnAeEPHQfAtOWQdBUsehw+uAvyTlW4+YyUbpzKK+Tdr/fVXY3GmCbPAsJfwqJgwrtw5e9cD9TNSoHDWz1u2j+uFcO6teHVlTYtqTGm7lhA+JMIDHsIJv8T8k/Da6NhwxyPm85I6UZWzjk+Wm/Tkhpj6oZPA0JExorIThHZLSKPX2C7i0WkSETGuy3LEJEtIrJRRLw3fVt91GUoTF8JcUPgHzPgH/dBQdlnH4YmtqF/XCteWZ5u05IaY+qEzwJCRAKBF4FrgF7ARBHpVcF2/wMs9nCYUao6QFWTfVVnvRHR1jXg38ifwYZ34LUr4fj5p6hLpiXd/90ZPtli05IaY3yvSgEhIuEiEuD83F1EbhSR4Ep2GwLsVtV0Vc0H5gLjPGz3APARYNOoBQTCFb+CSR/CqUzXfYltC0tXX+k2LalNKGSM8bWqXkGsAEJFpBOwBLgbeLOSfToBB9xeZzrLSjnHuxl42cP+CnwmIutEZGpFbyIiU0UkVURSs7KyKv0gDULSla45JqKTYN4dpQP+BQQI0y9PZMdhm5bUGON7VQ0IUdUzwC3AX1X1ZlzNRhfcx8Oy8r/2Pgc8pqqeuuYMU9VBuJqo7hORkZ7eRFVnqWqyqibHxMRUUlID0ioO7l4EQ6Y5A/5dB9kHuXFARzq1CmOmXUUYY3ysygEhIpcBk4BPnGVBleyTCcS5vY4Fyg9pmgzMFZEMYDwwU0RuAlDVQ873o8B8XE1WTUtQM7j2TzB+NhxJg1dGEJyxjGmXd2XdvhOssWlJjTE+VNWAeBj4BTBfVdNEpCtQ2dCka4EkEUkQkWbABGCh+waqmqCq8aoaD3wIzFDVBc49j0hw3f8ArgI8PyTQFPS5BaYug/C28PYtTDzzLm3DA5m5zIYCN8b4TmVXAQCo6nJgOYBzs/qYqj5YyT6FInI/rt5JgcAbTrhMd9Z7uu9Qoh0wX0RKanxXVRdVpdZGKzoJpiyBfz5K8Mr/4cOoS7lp12S2HuxBn04t/V2dMaYRkqq0Y4vIu8B0oAhYB7QEnlXVP/u2vOpJTk7W1NTG/cgEqrD+b+inP+doYThvx/2Wn/7kTn9XZYxpoERkXUWPElS1iamXqp4CbgI+BToDd3inPFMtIjB4MvKTf9MsNIyHDjzMsc//csEB/4wxpiaqGhDBznMPNwH/UNUCvt8jydSlDv0p+skylukgolc9CfPuhLxsf1dljGlEqhoQrwAZQDiwQkS6ABUPP2rqRHRMW1YO+gtPF01Cd3ziDPi3xd9lGWMaiSrdg/C4o0iQqtarCQqaxD2Icg58d4aUZ5bx677ZTD70WzhzHDoOhHZ9oH0faNcX2vVyTVhkjDHlXOgeRJV6MYlIS+AJoORhteXA7wBr0/CzuNbNGde/I/+zNYBxDywhav0LcGgDbPkAUl93thJok1g2NNr3gRadXPc0jDHGgyoFBPAGrucQfuC8vgOYjevJauNn01MS+fuGg8zedJpHxz7tWqgKJ/e55pg4stXV9HRoA2xbcH7HsCgnNPqeD4+YnhAU4pfPYYypX6oaEImqeqvb69+KyEYf1GNqoHs717Skf1udwdSRXYkICXJdGUTFu74uuv78xnmnXE9ll4TG4S2QOhsKneHFA4IguodzpeF2xRHRiIYxMcZUSVUD4qyIDFfVVQAiMgw4W8k+pg7NGNWNz7Z9wXtf72fKyK4VbxjaArpc5voqUVzkGlr8yJbzVxx7V8Dm989vE9HO7UrD+d6mGwRW9Z+QMaahqer/7unAW869CIATwF2+KcnUxIC4VgxNbMOrK9O547IuhAYHVn3ngECI6e766uN2oXj6eNnQOLwF0pdDcYFrfVAotL2obGi06w1hrbz62Ywx/lGtXkwi0gJAVU+JyMOq+pyvCquJptiLyd3qPcf44atfMyShNS9NGkSbCB/cSyjMh2M7y4bGka2u3lMlWnZ2BYZ7M1WreAiwGW6NqW8u1IupNt1c96tq51pV5mVNPSAAFmw4yGMfbSY6IoRZdw6md8c6GKdJFXK+dULD7Yrj+G5QZ3rUZpGuq4vS0OgLbXtBs+a+r88YUyFfBcQBVY2rfMu6YwHhsjnzJNPeXseJM/n8eXx/bujf0T+F5J+Bo9vLNVNthfwcZwOn+235exstOlr3W2PqiF1BNEFHc/KY8c56UvedYEZKIv91VQ8CA+rBSbe42NX9tiQsSpqpTu47v01J99t2vc/3xGrVBaK62AN/pmKqUJjn+sWk4AwUnIWC067vpcvc1hUVuJ4Fiuri+vcV0bZJ/mJS44AQkRw8j7kkQJiq1qsuLBYQZeUXFvPEwq28t+YAo3rE8H8TB9IitLKpxP0kL9vV/da9mSprp+s/uLvwGLfAiHf95y553aKT9aqqz4oKzp+c850Tt/sJu/yyMid692VuJ/4yy85QqyHigsKgVefzgVH+eyPtfOGTK4j6yALi+1SVd77ez28XptG5TXNevTOZxJgIf5dVNapw+pjr6uJExvmvktfZB8F9ttqAIGgZW0GAxEPz1k3yN8QaU3WdtE8fdf095B6F01mQn1vu5OzpJO/ht/eS3m/VEdzc7SvMdc+qzOtw1/cLLSu/T8kyCXD9Gzq5D07sO//v6uQ+OLEfzpUbKCK0ZdnAKPNz5wZ7P80CwvB1+nHunbOegsJinp84kFE92/q7pNorKoBTB53g2Fc2PE7sgzPHym7fLLLsFUeZAOnsOnk0dsXFcPY714m+5IRf8pXrBMFpZ3lu1vkHKD0JCHY7AYdBcLjnk7ink3TpSbzkewXL/BnoZ0+4BUe57yf3u5qz3IW3rfjqo2UsBNbPq3cLCANA5okzTH1rHdsPn+JnV/fg3ssTkcb8G/W5HNd/5IoCpPzJL6J9xQES2cH1vEh9VHjO7SRfcsIv91t/SQCcOV72qquEBEJ4tOskFx7tao8Pjzn/FeEsD4+BkEjXib6envDqhCrkHvEQHM7P2Zll/5wlAFrEVhwgEe381g3cAsKUOptfxM8+3MQ/N3/L9f068Ofx/QlrVk9PfL6k6jphugeGe4CcOni+iy64flsuaZ/2FCBhUd6t7VxOud/yPZzwSwKhfFNIieDmHk7wzok/ouTk77wOi7LnVLypqND1b8jT1ceJfZB7uOz2gSHQKs5zeJT8+/LRL3MWEKYMVeWl5Xv48+KdXNS+BbPuHExsVMNsP/WZwnw4lVnx1cfZ78puH9LSCQv3AElw/pN3dt0fOXO84qac8iFQdM5zXWGtq3DCd64ArMdX/VVwFk4eKHffwy1A8k6W3b6kedRjgNSud58FhPFo6Y6jPPjeBoKDApg5aRCXdm3j75IajrxTFV99fK99uuQ3Pw//1wKCKz7Bl2/iad6maTfrNCV52U5g7Pd8FVJwpuz2UfHw0KYavZUFhKnQnqxcpryVyv7jZ3jixt786JLOjfu+RF0oLna1T7sHSHFh2ZN+yRVAaCvrWWWqp3zvvpP7XFe8o35Ro8NZQJgLOpVXwEPvbWDpziwmDonjtzf2oVmQtUcb0xRcKCB8ehYQkbEislNEdovI4xfY7mIRKRKR8dXd19Rei9BgXrvrYmakJPLemgP88NWvyMqpoA3cGNNk+CwgRCQQeBG4BugFTBSRXhVs9z/A4urua7wnMED4+die/HXiQLYeyubGF1axOfOkv8syxviRL68ghgC7VTVdVfOBucA4D9s9AHwEHK3BvsbLbujfkQ+nDyVAhNte/pL5GzL9XZIxxk98GRCdgANurzOdZaVEpBNwM/Bydfc1vtOnU0sW3j+M/nGteOT9Tfz3p9spKm4896qMMVXjy4Dw1DWj/FnmOeAx1e892lmVfV0bikwVkVQRSc3Kyqp+lcajNhEhzPnJJdxxaRdmrUhn8uw1ZJ+pwVg6xpgGy5cBkQm4zxcRCxwqt00yMFdEMoDxwEwRuamK+wKgqrNUNVlVk2NiYrxUugEIDgzgqZv68PQtffkq/TjjXlzFN0dyKt/RGNMo+DIg1gJJIpIgIs2ACcBC9w1UNUFV41U1HvgQmKGqC6qyr6k7E4d05r0pl5J7roibXvyCf2874u+SjDF1wGcBoaqFwP24eidtB+apapqITBeR6TXZ11e1msolx7dm4f3D6BoTwZS3Unl+yTcU230JYxo1e1DOVEteQRG/+PsW5m84yDV92vPMbf0JD7FJeoxpqPz2oJxpfEKDA3n2B/35f9dexOK0w9z60moOfHem8h2NMQ2OBYSpNhFhysiuzL57CIdOnuWGF1axevexync0xjQoFhCmxi7vHsPC+4cTHRHCHW+sYfYXe2lMTZbGNHUWEKZW4qPDmT9jKKN6tOW3H2/j5x9u5lyhhxnLjDENjgWEqbXI0GBm3TGYB6/oxgfrMrn9la84ciqv8h2NMfWaBYTxioAA4dGrevDSpEHsOpLDDX9dxYb9J/xdljGmFiwgjFdd07cDH907lGZBAdz+yld8kHqg8p2MMfWSBYTxuos6tGDh/cNJjo/iZx9u5rcfp1FYVOzvsowx1WQBYXyidXgz3rpnCHcPi2f2FxncNXsNJ07n+7ssY0w1WEAYnwkKDOCJG3rzp/H9WLv3BDe+uIodh0/5uyxjTBVZQBif+0FyHHOnXcq5gmJumbmaRVu/9XdJxpgqsIAwdWJQ5yg+fmA43dtFMv2d9Tz771022J8x9ZwFhKkz7VqEMnfqpdw6KJbnl3zDtHfWkXuu0N9lGWMqYAFh6lRocCDP3NaP31zfi//sOMrNL35BxrHT/i7LGOOBBYSpcyLCPcMTeOueIWTlnuPGF1axYpdNF2tMfWMBYfxmWLdoFt43nA4tw5g8ew2vrUy3wf6MqUcsIIxfdW7TnL/PGMpVvdrz+0+28+i8TeQV2GB/xtQHFhDG78JDgpg5aRCPXtmd+RsO8oNXvuTb7LP+LsuYJs8CwtQLAQHCg6OTmHXHYPYczeWGv35BasZ3/i7LmCbNAsLUK1f1bs/8+4YRHhLIba98yf3vrmfXkRx/l2VMk2QBYeqd7u0iWXj/cO69PJGlO45y9XMruG/OenYetqAwpi5JY+o1kpycrKmpqf4uw3jRidP5vLYqnTe/yOB0fhHX9m3Pg6OT6Nm+hb9LM6ZREJF1qprscZ0FhGkITpzO5/VVe3lzdQa55woZ29sVFL06WlAYUxsXCgifNjGJyFgR2Skiu0XkcQ/rx4nIZhHZKCKpIjLcbV2GiGwpWefLOk39FxXejJ9e3YNVj43iwSu68cXuY1z7/EqmvZ1K2qFsf5dnTKPksysIEQkEdgFXApnAWmCiqm5z2yYCOK2qKiL9gHmq2tNZlwEkq+qxqr6nXUE0HdlnCnj9i73M/mIvOXmFXNmrHQ+NTqJPp5b+Ls2YBsVfVxBDgN2qmq6q+cBcYJz7Bqqaq+cTKhxoPO1dxqdaNg/m0Su7s+qxK3h4TBJfpR/n+r+u4id/S2VLpl1RGOMNvgyIToD7hMSZzrIyRORmEdkBfALc47ZKgc9EZJ2ITK3oTURkqtM8lZqVZeP5NDUtw4J5eIwrKB4Z0501e49zwwur+PGba9mcedLf5RnToPkyIMTDsu9dIajqfKdZ6SbgKbdVw1R1EHANcJ+IjPT0Jqo6S1WTVTU5JibGC2WbhqhlWDAPjUli1eNX8F9Xdid13wlufOEL7nlzLZsOnPR3ecY0SL4MiEwgzu11LHCooo1VdQWQKCLRzutDzvejwHxcTVbGXFCL0GAeGJ3EqsdG8bOre7B+/wnGvfgFk2evYcP+E/4uz5gGxZcBsRZIEpEEEWkGTAAWum8gIt1ERJyfBwHNgOMiEi4ikc7ycOAqYKsPazWNTGRoMPeN6saqx67gZ1f3YNOBk9w8czV3vbGG9RYUxlRJkK8OrKqFInI/sBgIBN5Q1TQRme6sfxm4FbhTRAqAs8DtTo+mdsB8JzuCgHdVdZGvajWNV0RIEPeN6sZdQ+N5+8t9vLoynVtmrmZEUjQPj0licJfW/i7RmHrLHpQzTcrpc4W8/dU+Zq1I57vT+YxIiuah0Ukkx1tQmKbJnqQ2ppwz+YW84wTFsdx8hnVrw0OjuzMkwYLCNC0WEMZU4Ex+IXO+2s8rK/ZwLDefoYlteGh0Epd0bePv0oypExYQxlTibH4Rc77ex8vL0zmWe45Lu7bmodHduSzRgsI0bhYQxlTR2fwi3l2zn5eX7yEr5xyXJLTmoTFJXNa1DU6nCWMaFQsIY6opr6CI99bs56Vleziac44h8a15eEwSlyVaUJjGxQLCmBrKKyhi7pr9vLR8D0dOnePi+CgeGt2dYd0sKEzjYAFhTC3lFRQxL/UAM5fu4fCpPAZ3ieLhMUkM7xZtQWEaNAsIY7zkXGER81Izmbl0N99m5zGocyseGtOdkUkWFKZhsoAwxsvOFRbxgRMUh7LzGBDXiofHJHF59xgLCtOgWEAY4yP5hcV8uC6TF5fu5uDJs/SPa8XDo5NI6WFBYRoGCwhjfCy/sJiP1ruCIvPEWfrHtuShMUmM6tHWgsLUaxYQxtSRgqJi/r4+k7/+xxUU/WJb8uAVSYy+yILC1E8WEMbUsYKiYuavP8gLS3ez/7szJESHM7ZPe67u3Z7+sS0tLEy9YQFhjJ8UFBWzcOMhFmw8yJd7jlNYrHRoGcpVvdpxde/2DEloTVCgL6dlMebCLCCMqQeyzxSwZMcRFm09zIpvssgrKCaqeTCjL2rH2N7tGZ4UTWhwoL/LNE2MBYQx9cyZ/EJW7MpicdoRPt9+hJy8Qpo3CySlRwxX927PqJ5taREa7O8yTRNwoYDw2YxyxpiKNW8WxNg+HRjbpwP5hcV8lX6cxWmH+WzbET7dcpjgQGFYt2iu7t2eK3u1IzoixN8lmybIriCMqUeKi5UNB06wOM3VFLX/uzMECCR3ac3Vfdpzde92xEY193eZphGxJiZjGiBVZcfhHBZtPczitMPsOJwDQO+OLRjbuz1X92lPUtsI6xFlasUCwphGYN/x0yxOO8yirYdZv/8kAF2jw7mqt+vKon9sKwICLCxM9VhAGNPIHD2Vx2fbjrA47XBp99n2LUK5qrerR5R1nzVVZQFhTCNW0n12cdphlu9ydZ9t1TyYMRe5nrUYYd1nzQX4LSBEZCzwf0Ag8Jqq/rHc+nHAU0AxUAg8rKqrqrKvJxYQpqk7m1/E8l1ZfJZ2mM+3H+GUdZ81lfBLQIhIILALuBLIBNYCE1V1m9s2EcBpVVUR6QfMU9WeVdnXEwsIY84rKHJ1n1201dV9NivnHMGBwtDEaMb2ac+Yi9oRE2ndZ5s6fz0HMQTYrarpThFzgXFA6UleVXPdtg8HtKr7GmMuLDgwgBFJMYxIiuGpcX3KdJ/9xd+38EvZwsVdWnNVb1dTVFxr6z5ryvJlQHQCDri9zgQuKb+RiNwMPA20Ba6rzr7GmKoJCBAGd2nN4C6t+cU1PdlxOKe0R9TvP9nO7z/ZTu+OLbi6d3vGWvdZ4/BlQHj61/W99ixVnQ/MF5GRuO5HjKnqvgAiMhWYCtC5c+caF2tMUyEiXNShBRd1aMHDY7qXdp9dnHaEv3y+i2f/vYuE6HCutu6zTZ4vAyITiHN7HQscqmhjVV0hIokiEl2dfVV1FjALXPcgalu0MU1NlzbhTB2ZyNSRiWW6z762Mp2Xl+8p7T5bMvpssHWfbTJ8eZM6CNeN5tHAQVw3mn+oqmlu23QD9jg3qQcBH+MKg8DK9vXEblIb4z3ZZwr4z07XPQv37rN9O7UkMSaCxLYRdIuJILFtODERIdYk1UD55Sa1qhaKyP3AYlwn/DdUNU1EpjvrXwZuBe4UkQLgLHC7uhLL476+qtUY830tmwdz88BYbh4YW9p9dsn2I+w4nMO81AOcyS8q3bZFaBCJbSNIjImgm9v3uKgwe2CvAbMH5Ywx1aaqHD6Vx+6juew5msvurFz2HD3NnqxcjuacK90uOFCIbxNeJjQSYyLoGhNOeIgNJl0f2HDfxhivEhE6tAyjQ8swRiTFlFmXfbaA9KxcV3hkuUJj5+EcPtt2hKLi87+QdmwZWnrV4fruChJrrqo/LCCMMV7VMiyYgZ2jGNg5qszy/MJi9h13BcaerNNOgOTyQeoBTrs1V0WGBpVeaZy/6ginc+vm1lxVxywgjDF1ollQAEntIklqF1lmeUlz1Z6jp9l9NKc0PFbsyuLDdZml25U0V5WGRttwusVEWnOVD9mfqjHGr9ybq4YnRZdZdyqvgD1uTVW7j+ay62gO/95etrmqQ8tQt6uO8NIeVjGR1lxVGxYQxph6q0Voxc1V+787zW7nxnjJjXJPzVXuN8dL7nNYc1XVWEAYYxqcZkEBdGsbSbe232+uOnLqXOn9jZLvK7/x3Fz1wg8H0aN9ZPnDG4cFhDGm0RAR2rcMpX3LUI/NVeluN8f3HM2ldXgzP1XaMFhAGGOahBahwQyIa8WAuFb+LqXBsEY4Y4wxHllAGGOM8cgCwhhjjEcWEMYYYzyygDDGGOORBYQxxhiPLCCMMcZ4ZAFhjDHGo0Y1YZCIZAH7arh7NHDMi+X4U2P5LI3lc4B9lvqosXwOqN1n6aKqMZ5WNKqAqA0RSa1oVqWGprF8lsbyOcA+S33UWD4H+O6zWBOTMcYYjywgjDHGeGQBcd4sfxfgRY3lszSWzwH2WeqjxvI5wEefxe5BGGOM8ciuIIwxxnhkAWGMMcajJh8QIjJWRHaKyG4Redzf9dSUiLwhIkdFZKu/a6ktEYkTkaUisl1E0kTkIX/XVFMiEioia0Rkk/NZfuvvmmpDRAJFZIOI/NPftdSGiGSIyBYR2Sgiqf6upzZEpJWIfCgiO5z/M5d57dhN+R6EiAQCu4ArgUxgLTBRVbf5tbAaEJGRQC7wlqr28Xc9tSEiHYAOqrpeRCKBdcBNDfTvRYBwVc0VkWBgFfCQqn7l59JqREQeBZKBFqp6vb/rqSkRyQCSVbXBPygnIn8DVqrqayLSDGiuqie9ceymfgUxBNitqumqmg/MBcb5uaYaUdUVwHf+rsMbVPVbVV3v/JwDbAc6+beqmlGXXOdlsPPVIH8rE5FY4DrgNX/XYlxEpAUwEngdQFXzvRUOYAHRCTjg9jqTBnoiaqxEJB4YCHzt51JqzGmW2QgcBf6tqg31szwH/Bwo9nMd3qDAZyKyTkSm+ruYWugKZAGznaa/10Qk3FsHb+oBIR6WNcjf7hojEYkAPgIeVtVT/q6nplS1SFUHALHAEBFpcE2AInI9cFRV1/m7Fi8ZpqqDgGuA+5wm2oYoCBgEvKSqA4HTgNfupTb1gMgE4txexwKH/FSLceO0138EzFHVv/u7Hm9wLv2XAWP9W0mNDANudNru5wJXiMg7/i2p5lT1kPP9KDAfV3NzQ5QJZLpdlX6IKzC8oqkHxFogSUQSnJs7E4CFfq6pyXNu7L4ObFfVZ/1dT22ISIyItHJ+DgPGADv8WlQNqOovVDVWVeNx/T/5j6r+yM9l1YiIhDudH3CaY64CGmTvP1U9DBwQkR7OotGA1zpzBHnrQA2RqhaKyP3AYiAQeENV0/xcVo2IyHtAChAtIpnAE6r6un+rqrFhwB3AFqftHuCXqvqp/0qqsQ7A35wecwHAPFVt0F1EG4F2wHzX7yEEAe+q6iL/llQrDwBznF9y04G7vXXgJt3N1RhjTMWaehOTMcaYClhAGGOM8cgCwhhjjEcWEMYYYzyygDDGGOORBYRp1EQkt/KtanX8T0uec6jlcQJE5HkR2eqMMrpWRBKcdb+sdaHG1IB1czWNmojkqmqEv+uojIhMBG4FfqCqxc7AeKdV9URD+Qym8bErCNPkiMgAEflKRDaLyHwRiXKWX+ws+1JE/lwyt4aINBeRec6690XkaxFJdtZliEi0iMQ7Y/G/6sz78Jnz5HSFxy2nA/CtqhYDqGqmEw5/BMKceQvmOMf7kTPHxEYRecV5CA8RyRWR/xWR9SKyRERinOUPisg2p4a5Pv7jNY2IBYRpit4CHlPVfsAW4Aln+WxguqpeBhS5bT8DOOFs/xQwuILjJgEvqmpv4CSuK4ILHdfdPOAG56T/vyIyEEBVHwfOquoAVZ0kIhcBt+MabG6Ac7xJzjHCgfXOIHTL3T7X48BAp/7plfzZGFPKAsI0KSLSEmilqsudRX8DRjr3ESJVdbWz/F233YbjGqAOVd0KbK7g8HtVdaPz8zogvpLjllLVTKAH8Atcw2kvEZHRHjYdjSug1jrDkIzGNeQzzn7vOz+/49SNU+8cEfkRUFhB7cZ8T5Mei8kYN56Gfq/KOnfn3H4uAsKqsS+qeg74F/AvETkC3AQs8VDL31T1F1U5pPP9OlyTytwI/FpEequqBYWplF1BmCZFVbOBEyIywll0B7BcVU8AOSJyqbN8gttuq4AfAIhIL6BvNd7vQsctJSKDRKSj83MA0A/Y56wucIY/B1dgjBeRts62rUWki7MuABjv/PxDYJVzrDhVXYprsp9WgN3wNlViVxCmsWvujG5b4lngLuBlEWlO2dEvfwy8KiKncc3bkO0sn4lrRNbNwAZcTTbZVF1Fx3XX1tkmxHm9BnjB+XkWsFlE1jv3IX6Faza0AKAAuA9XmJwGeovIOuc9bsc1SvE7TtOaAH/x5pSUpnGzbq7GOEQkomT+aBF5HOigqg85vYSCVTVPRBJx/Rbf3ZnHvMbH9UH91h3WeJVdQRhz3nUi8gtc/y/2AZOd5c2BpU4zjwD3VjUcKjmuMfWaXUEYY4zxyG5SG2OM8cgCwhhjjEcWEMYYYzyygDDGGOORBYQxxhiP/j/ZNoVYNcrzkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Evaluation:\n",
      "Evaluation Loss: 0.36886531114578247\n",
      "Evaluation Accuracy: 0.8600508905852418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.87       437\n",
      "           1       0.87      0.89      0.88       353\n",
      "           2       0.80      0.86      0.83       389\n",
      "\n",
      "    accuracy                           0.86      1179\n",
      "   macro avg       0.86      0.86      0.86      1179\n",
      "weighted avg       0.86      0.86      0.86      1179\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Incorrect positive samples:\n",
      "1. sentences\n",
      "2. probabilities\n",
      "\n",
      "Incorrect negative samples:\n",
      "1. sentences\n",
      "2. probabilities\n",
      "\n",
      "Incorrect neutral samples:\n",
      "1. sentences\n",
      "2. probabilities\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Train with the best parameters\n",
    "best_params = study.best_params\n",
    "trainer = train_with_best_params(train_dataset_t, val_dataset_t,model, best_params)\n",
    "\n",
    "# Save the model after optimization\n",
    "trainer.save_model(\"model_after_optimization\")\n",
    "model.config.to_json_file(\"model_after_optimization/config.json\")\n",
    "tokenizer.save_pretrained(\"model_after_optimization\")\n",
    "\n",
    "# Print the results after training with the best parameters\n",
    "results = trainer.evaluate()\n",
    "print(\"\\nTraining with Best Parameters:\")\n",
    "print(f\"Evaluation Loss: {results['eval_loss']}\")\n",
    "print(f\"Evaluation Accuracy: {results['eval_accuracy']}\")\n",
    "\n",
    "# Plot the losses\n",
    "plot_losses(trainer)\n",
    "\n",
    "# Test on the test dataset and print report and confusion matrix\n",
    "test_model(trainer, test_dataset_t, y_true_t, label_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69990828-32e3-4277-bfbd-939dc8ba6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to get specificity and FPR, need to enter the confusion matrix manually to get the results from the above. As best parameters can change based on the trails. \n",
    "cm = np.array([[366, 10, 61], \n",
    "               [14, 314, 25], \n",
    "               [20, 35, 334]])\n",
    "\n",
    "compute_FPR_spec_metrics(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b5434-abe6-47f6-a3a6-ab5fae974816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract incorrect samples\n",
    "incorrect_samples = extract_incorrect_samples(trainer, test_dataset_t, label_encoder, tokenizer)\n",
    "\n",
    "# Print the sentences and probabilities\n",
    "for label, data in incorrect_samples.items():\n",
    "    print(f\"\\nIncorrect {label} samples:\")\n",
    "    for idx, (sentence, prob) in enumerate(zip(data['sentences'], data['probabilities']), 1):\n",
    "        print(f\"{idx}. {sentence} (Probability: {prob:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56668006-28fe-4b7c-a1ec-486cfd357e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7493ee09-b6c4-4a36-84f7-823015d8b3a3",
   "metadata": {},
   "source": [
    "### Reloading the trained model, to print the results properly in the format required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e50a25fc-aa86-47e5-abe8-9d27f4f53e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "\n",
    "# Load model, configuration, and tokenizer\n",
    "config = AutoConfig.from_pretrained(\"model_after_optimization/config.json\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"model_after_optimization\", config=config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model_after_optimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d114b89-f244-4324-ab55-21548efa22a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = process_dataframe(processed_df)\n",
    "label_encoder = LabelEncoder()\n",
    "y_t = label_encoder.fit_transform(processed_df['Target'].values)\n",
    "X_t = processed_df['Headlines'].values\n",
    "\n",
    "train_dataset_t, val_dataset_t, test_dataset_t, y_true_t = prepare_dataset(X_t, y_t, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7ae7566-2419-417d-b9f9-2f5099d8ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Set up training arguments (assuming you still have best_params from the optimization)\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=\"model_dir\",\n",
    "        use_mps_device=True,\n",
    "        num_train_epochs=9,\n",
    "        per_device_train_batch_size=32,\n",
    "        learning_rate=0.0010710659975038334,\n",
    "        weight_decay=0.07830680597137599,\n",
    "        warmup_steps=210,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        save_steps=500,\n",
    "        logging_steps=250,\n",
    "        metric_for_best_model='accuracy',\n",
    "        greater_is_better=True,\n",
    ")\n",
    "\n",
    "# Recreate the trainer\n",
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset_t,\n",
    "        eval_dataset=val_dataset_t,\n",
    "        compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73dcc5a0-b145-4f83-be82-e76bc8453378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with Best Parameters:\n",
      "Evaluation Loss: 0.40909987688064575\n",
      "Evaluation Accuracy: 0.8447837150127226\n",
      "\n",
      "Test Set Evaluation:\n",
      "Evaluation Loss: 0.36886531114578247\n",
      "Evaluation Accuracy: 0.8600508905852418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9150    0.8375    0.8746       437\n",
      "           1     0.8747    0.8895    0.8820       353\n",
      "           2     0.7952    0.8586    0.8257       389\n",
      "\n",
      "    accuracy                         0.8601      1179\n",
      "   macro avg     0.8616    0.8619    0.8608      1179\n",
      "weighted avg     0.8634    0.8601    0.8607      1179\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate and print the results\n",
    "results = trainer.evaluate()\n",
    "print(\"\\nTraining with Best Parameters:\")\n",
    "print(f\"Evaluation Loss: {results['eval_loss']}\")\n",
    "print(f\"Evaluation Accuracy: {results['eval_accuracy']}\")\n",
    "\n",
    "# Test on the test dataset and print the report and confusion matrix\n",
    "test_model(trainer, test_dataset_t, y_true_t, label_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5b171e7-796e-411b-8635-6f1a0221a7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for class positive (Class value: 0):\n",
      "Specificity: 0.9501\n",
      "FPR: 0.0499\n",
      "Precision: 0.915\n",
      "\n",
      "Metrics for class negative (Class value: 1):\n",
      "Specificity: 0.9396\n",
      "FPR: 0.0604\n",
      "Precision: 0.8747\n",
      "\n",
      "Metrics for class neutral (Class value: 2):\n",
      "Specificity: 0.8877\n",
      "FPR: 0.1123\n",
      "Precision: 0.7952\n",
      "\n",
      "Overall accuracy: 0.8601\n",
      "Weighted average specificity: 0.9264\n",
      "Weighted average FPR: 0.0736\n",
      "Macro average specificity: 0.9258\n",
      "Macro average FPR: 0.0742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = np.array([[366, 10, 61], \n",
    "               [14, 314, 25], \n",
    "               [20, 35, 334]])\n",
    "\n",
    "compute_FPR_spec_metrics(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03cc845c-1bc4-43d7-9fab-2252d1274259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Incorrect positive samples:\n",
      "1. oil prices tumble to 45 bring cheer to customers (Probability: -1.6323)\n",
      "2. rupee trims initial losses trades at 6235 vs dlr (Probability: 2.3520)\n",
      "3. hefty fine for insider trade looms over reliance industries (Probability: -0.5291)\n",
      "4. fii buying in vmart retail crosses limit no further purchase (Probability: -1.7944)\n",
      "5. dtc proposal to create volatility in stock markets analysts (Probability: 1.2210)\n",
      "\n",
      "Incorrect negative samples:\n",
      "1. omc should be a part of an investors portfolio mehraboon irani (Probability: -0.5123)\n",
      "2. kingfisher at yearhigh on report of wilbur ross investment plan (Probability: -1.5060)\n",
      "3. rupee trims losses against us dollar still trading 2 paise down (Probability: 2.9256)\n",
      "4. leisure revenue buoys cox kings (Probability: -1.7944)\n",
      "5. punters make a killing in geometric (Probability: -0.2987)\n",
      "\n",
      "Incorrect neutral samples:\n",
      "1. investors may not gain much from new structure of crompton greaves (Probability: 2.6486)\n",
      "2. inflation corporate governance biggest market worries blackstone asia advisors (Probability: -2.1220)\n",
      "3. nifty unlikely to get past the 75507560 mark ashwani gujral (Probability: 2.9256)\n",
      "4. euro steadies after slumping on dovish draghi comments (Probability: 1.6062)\n",
      "5. recommend wait and watch for midcap it stocks dipan mehta (Probability: -0.2987)\n"
     ]
    }
   ],
   "source": [
    "# Extract incorrect samples\n",
    "incorrect_samples = extract_incorrect_samples(trainer, test_dataset_t, label_encoder, tokenizer)\n",
    "\n",
    "# Print the sentences and probabilities\n",
    "for label, data in incorrect_samples.items():\n",
    "    print(f\"\\nIncorrect {label} samples:\")\n",
    "    for idx, (sentence, prob) in enumerate(zip(data['sentences'], data['probabilities']), 1):\n",
    "        print(f\"{idx}. {sentence} (Probability: {prob:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ea742f-9b4a-4dfb-9cea-9a41de580cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
